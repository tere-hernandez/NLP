{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Accessing Text Corpora and Lexical Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El corpus de un texto, significa un conjunto de materiales (textos, libros, documentos, etc) sobre un tema en particular.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = gutenberg.words('austen-emma.txt')\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 37 matches:\n",
      "er father , was sometimes taken by surprize at his being still able to pity ` \n",
      "hem do the other any good .\" \" You surprize me ! Emma must do Harriet good : a\n",
      "Knightley actually looked red with surprize and displeasure , as he stood up ,\n",
      "r . Elton , and found to his great surprize , that Mr . Elton was actually on \n",
      "d aid .\" Emma saw Mrs . Weston ' s surprize , and felt that it must be great ,\n",
      "father was quite taken up with the surprize of so sudden a journey , and his f\n",
      "y , in all the favouring warmth of surprize and conjecture . She was , moreove\n",
      "he appeared , to have her share of surprize , introduction , and pleasure . Th\n",
      "ir plans ; and it was an agreeable surprize to her , therefore , to perceive t\n",
      "talking aunt had taken me quite by surprize , it must have been the death of m\n",
      "f all the dialogue which ensued of surprize , and inquiry , and congratulation\n",
      " the present . They might chuse to surprize her .\" Mrs . Cole had many to agre\n",
      "the mode of it , the mystery , the surprize , is more like a young woman ' s s\n",
      " to her song took her agreeably by surprize -- a second , slightly but correct\n",
      "\" \" Oh ! no -- there is nothing to surprize one at all .-- A pretty fortune ; \n",
      "t to be considered . Emma ' s only surprize was that Jane Fairfax should accep\n",
      "of your admiration may take you by surprize some day or other .\" Mr . Knightle\n",
      "ation for her will ever take me by surprize .-- I never had a thought of her i\n",
      " expected by the best judges , for surprize -- but there was great joy . Mr . \n",
      " sound of at first , without great surprize . \" So unreasonably early !\" she w\n",
      "d Frank Churchill , with a look of surprize and displeasure .-- \" That is easy\n",
      "; and Emma could imagine with what surprize and mortification she must be retu\n",
      "tled that Jane should go . Quite a surprize to me ! I had not the least idea !\n",
      " . It is impossible to express our surprize . He came to speak to his father o\n",
      "g engaged !\" Emma even jumped with surprize ;-- and , horror - struck , exclai\n"
     ]
    }
   ],
   "source": [
    "emma = nltk.Text(gutenberg.words('austen-emma.txt'))\n",
    "emma.concordance(\"surprize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 25 26 austen-emma.txt\n",
      "5 26 17 austen-persuasion.txt\n",
      "5 28 22 austen-sense.txt\n",
      "4 34 79 bible-kjv.txt\n",
      "5 19 5 blake-poems.txt\n",
      "4 19 14 bryant-stories.txt\n",
      "4 18 12 burgess-busterbrown.txt\n",
      "4 20 13 carroll-alice.txt\n",
      "5 20 12 chesterton-ball.txt\n",
      "5 23 11 chesterton-brown.txt\n",
      "5 18 11 chesterton-thursday.txt\n",
      "4 21 25 edgeworth-parents.txt\n",
      "5 26 15 melville-moby_dick.txt\n",
      "5 52 11 milton-paradise.txt\n",
      "4 12 9 shakespeare-caesar.txt\n",
      "4 12 8 shakespeare-hamlet.txt\n",
      "4 12 7 shakespeare-macbeth.txt\n",
      "5 36 12 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk.corpus.reader in nltk.corpus:\n",
      "\n",
      "NAME\n",
      "    nltk.corpus.reader\n",
      "\n",
      "DESCRIPTION\n",
      "    NLTK corpus readers.  The modules in this package provide functions\n",
      "    that can be used to read corpus fileids in a variety of formats.  These\n",
      "    functions can be used to read both the corpus fileids that are\n",
      "    distributed in the NLTK corpus package, and corpus fileids that are part\n",
      "    of external corpora.\n",
      "    \n",
      "    Corpus Reader Functions\n",
      "    =======================\n",
      "    Each corpus module defines one or more \"corpus reader functions\",\n",
      "    which can be used to read documents from that corpus.  These functions\n",
      "    take an argument, ``item``, which is used to indicate which document\n",
      "    should be read from the corpus:\n",
      "    \n",
      "    - If ``item`` is one of the unique identifiers listed in the corpus\n",
      "      module's ``items`` variable, then the corresponding document will\n",
      "      be loaded from the NLTK corpus package.\n",
      "    - If ``item`` is a fileid, then that file will be read.\n",
      "    \n",
      "    Additionally, corpus reader functions can be given lists of item\n",
      "    names; in which case, they will return a concatenation of the\n",
      "    corresponding documents.\n",
      "    \n",
      "    Corpus reader functions are named based on the type of information\n",
      "    they return.  Some common examples, and their return types, are:\n",
      "    \n",
      "    - words(): list of str\n",
      "    - sents(): list of (list of str)\n",
      "    - paras(): list of (list of (list of str))\n",
      "    - tagged_words(): list of (str,str) tuple\n",
      "    - tagged_sents(): list of (list of (str,str))\n",
      "    - tagged_paras(): list of (list of (list of (str,str)))\n",
      "    - chunked_sents(): list of (Tree w/ (str,str) leaves)\n",
      "    - parsed_sents(): list of (Tree with str leaves)\n",
      "    - parsed_paras(): list of (list of (Tree with str leaves))\n",
      "    - xml(): A single xml ElementTree\n",
      "    - raw(): unprocessed corpus contents\n",
      "    \n",
      "    For example, to read a list of the words in the Brown Corpus, use\n",
      "    ``nltk.corpus.brown.words()``:\n",
      "    \n",
      "        >>> from nltk.corpus import brown\n",
      "        >>> print(\", \".join(brown.words()))\n",
      "        The, Fulton, County, Grand, Jury, said, ...\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    aligned\n",
      "    api\n",
      "    bnc\n",
      "    bracket_parse\n",
      "    categorized_sents\n",
      "    chasen\n",
      "    childes\n",
      "    chunked\n",
      "    cmudict\n",
      "    comparative_sents\n",
      "    conll\n",
      "    crubadan\n",
      "    dependency\n",
      "    framenet\n",
      "    ieer\n",
      "    indian\n",
      "    ipipan\n",
      "    knbc\n",
      "    lin\n",
      "    mte\n",
      "    nkjp\n",
      "    nombank\n",
      "    nps_chat\n",
      "    opinion_lexicon\n",
      "    panlex_lite\n",
      "    panlex_swadesh\n",
      "    pl196x\n",
      "    plaintext\n",
      "    ppattach\n",
      "    propbank\n",
      "    pros_cons\n",
      "    reviews\n",
      "    rte\n",
      "    semcor\n",
      "    senseval\n",
      "    sentiwordnet\n",
      "    sinica_treebank\n",
      "    string_category\n",
      "    switchboard\n",
      "    tagged\n",
      "    timit\n",
      "    toolbox\n",
      "    twitter\n",
      "    udhr\n",
      "    util\n",
      "    verbnet\n",
      "    wordlist\n",
      "    wordnet\n",
      "    xmldocs\n",
      "    ycoe\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "            nltk.corpus.reader.bracket_parse.CategorizedBracketParseCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.bracket_parse.BracketParseCorpusReader)\n",
      "            nltk.corpus.reader.categorized_sents.CategorizedSentencesCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "            nltk.corpus.reader.pl196x.Pl196xCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "            nltk.corpus.reader.plaintext.CategorizedPlaintextCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.plaintext.PlaintextCorpusReader)\n",
      "                nltk.corpus.reader.plaintext.PortugueseCategorizedPlaintextCorpusReader\n",
      "            nltk.corpus.reader.pros_cons.ProsConsCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "            nltk.corpus.reader.tagged.CategorizedTaggedCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.tagged.TaggedCorpusReader)\n",
      "        nltk.corpus.reader.api.CorpusReader\n",
      "            nltk.corpus.reader.aligned.AlignedCorpusReader\n",
      "            nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "                nltk.corpus.reader.bracket_parse.BracketParseCorpusReader\n",
      "                    nltk.corpus.reader.bracket_parse.AlpinoCorpusReader\n",
      "                nltk.corpus.reader.dependency.DependencyCorpusReader\n",
      "                nltk.corpus.reader.knbc.KNBCorpusReader\n",
      "                nltk.corpus.reader.sinica_treebank.SinicaTreebankCorpusReader\n",
      "            nltk.corpus.reader.chasen.ChasenCorpusReader\n",
      "            nltk.corpus.reader.chunked.ChunkedCorpusReader\n",
      "            nltk.corpus.reader.cmudict.CMUDictCorpusReader\n",
      "            nltk.corpus.reader.comparative_sents.ComparativeSentencesCorpusReader\n",
      "            nltk.corpus.reader.conll.ConllCorpusReader\n",
      "                nltk.corpus.reader.conll.ConllChunkCorpusReader\n",
      "            nltk.corpus.reader.crubadan.CrubadanCorpusReader\n",
      "            nltk.corpus.reader.ieer.IEERCorpusReader\n",
      "            nltk.corpus.reader.indian.IndianCorpusReader\n",
      "            nltk.corpus.reader.ipipan.IPIPANCorpusReader\n",
      "            nltk.corpus.reader.lin.LinThesaurusCorpusReader\n",
      "            nltk.corpus.reader.nombank.NombankCorpusReader\n",
      "            nltk.corpus.reader.panlex_lite.PanLexLiteCorpusReader\n",
      "            nltk.corpus.reader.plaintext.PlaintextCorpusReader\n",
      "                nltk.corpus.reader.plaintext.EuroparlCorpusReader\n",
      "                nltk.corpus.reader.udhr.UdhrCorpusReader\n",
      "            nltk.corpus.reader.ppattach.PPAttachmentCorpusReader\n",
      "            nltk.corpus.reader.propbank.PropbankCorpusReader\n",
      "            nltk.corpus.reader.reviews.ReviewsCorpusReader\n",
      "            nltk.corpus.reader.senseval.SensevalCorpusReader\n",
      "            nltk.corpus.reader.sentiwordnet.SentiWordNetCorpusReader\n",
      "            nltk.corpus.reader.string_category.StringCategoryCorpusReader\n",
      "            nltk.corpus.reader.switchboard.SwitchboardCorpusReader\n",
      "            nltk.corpus.reader.tagged.TaggedCorpusReader\n",
      "                nltk.corpus.reader.mte.MTECorpusReader\n",
      "                nltk.corpus.reader.tagged.MacMorphoCorpusReader\n",
      "                nltk.corpus.reader.tagged.TimitTaggedCorpusReader\n",
      "            nltk.corpus.reader.timit.TimitCorpusReader\n",
      "            nltk.corpus.reader.toolbox.ToolboxCorpusReader\n",
      "            nltk.corpus.reader.twitter.TwitterCorpusReader\n",
      "            nltk.corpus.reader.wordlist.WordListCorpusReader\n",
      "                nltk.corpus.reader.opinion_lexicon.OpinionLexiconCorpusReader\n",
      "                nltk.corpus.reader.panlex_swadesh.PanlexSwadeshCorpusReader\n",
      "                nltk.corpus.reader.wordlist.MWAPPDBCorpusReader\n",
      "                nltk.corpus.reader.wordlist.NonbreakingPrefixesCorpusReader\n",
      "                nltk.corpus.reader.wordlist.SwadeshCorpusReader\n",
      "                nltk.corpus.reader.wordlist.UnicharsCorpusReader\n",
      "            nltk.corpus.reader.wordnet.WordNetCorpusReader\n",
      "            nltk.corpus.reader.wordnet.WordNetICCorpusReader\n",
      "            nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "                nltk.corpus.reader.bnc.BNCCorpusReader\n",
      "                nltk.corpus.reader.childes.CHILDESCorpusReader\n",
      "                nltk.corpus.reader.framenet.FramenetCorpusReader\n",
      "                nltk.corpus.reader.nkjp.NKJPCorpusReader\n",
      "                nltk.corpus.reader.nps_chat.NPSChatCorpusReader\n",
      "                nltk.corpus.reader.rte.RTECorpusReader\n",
      "                nltk.corpus.reader.semcor.SemcorCorpusReader\n",
      "                nltk.corpus.reader.verbnet.VerbnetCorpusReader\n",
      "            nltk.corpus.reader.ycoe.YCOECorpusReader\n",
      "        nltk.corpus.reader.sentiwordnet.SentiSynset\n",
      "    nltk.corpus.reader.util.StreamBackedCorpusView(nltk.collections.AbstractLazySequence)\n",
      "        nltk.corpus.reader.pl196x.TEICorpusView\n",
      "    \n",
      "    class AlignedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  AlignedCorpusReader(root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), alignedsent_block_reader=<function read_alignedsent_block at 0x00000207D8B815E8>, encoding='latin1')\n",
      "     |  \n",
      "     |  Reader for corpora of word-aligned sentences.  Tokens are assumed\n",
      "     |  to be separated by whitespace.  Sentences begin on separate lines.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AlignedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), alignedsent_block_reader=<function read_alignedsent_block at 0x00000207D8B815E8>, encoding='latin1')\n",
      "     |      Construct a new Aligned Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = AlignedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  aligned_sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of AlignedSent objects.\n",
      "     |      :rtype: list(AlignedSent)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class AlpinoCorpusReader(BracketParseCorpusReader)\n",
      "     |  AlpinoCorpusReader(root, encoding='ISO-8859-1', tagset=None)\n",
      "     |  \n",
      "     |  Reader for the Alpino Dutch Treebank.\n",
      "     |  This corpus has a lexical breakdown structure embedded, as read by _parse\n",
      "     |  Unfortunately this puts punctuation and some other words out of the sentence\n",
      "     |  order in the xml element tree. This is no good for tag_ and word_\n",
      "     |  _tag and _word will be overridden to use a non-default new parameter 'ordered'\n",
      "     |  to the overridden _normalize function. The _parse function can then remain\n",
      "     |  untouched.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AlpinoCorpusReader\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='ISO-8859-1', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param comment_char: The character which can appear at the start of\n",
      "     |          a line to indicate that the rest of the line is a comment.\n",
      "     |      :param detect_blocks: The method that is used to find blocks\n",
      "     |        in the corpus; can be 'unindented_paren' (every unindented\n",
      "     |        parenthesis starts a new parse) or 'sexpr' (brackets are\n",
      "     |        matched).\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class BNCCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  BNCCorpusReader(root, fileids, lazy=True)\n",
      "     |  \n",
      "     |  Corpus reader for the XML version of the British National Corpus.\n",
      "     |  \n",
      "     |  For access to the complete XML data structure, use the ``xml()``\n",
      "     |  method.  For access to simple word lists and tagged word lists, use\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()``, and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  You can obtain the full version of the BNC corpus at\n",
      "     |  http://www.ota.ox.ac.uk/desc/2554\n",
      "     |  \n",
      "     |  If you extracted the archive to a directory called `BNC`, then you can\n",
      "     |  instantiate the reader as::\n",
      "     |  \n",
      "     |      BNCCorpusReader(root='BNC/Texts/', fileids=r'[A-K]/\\w*/\\w*\\.xml')\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BNCCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |      \n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, c5=False, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |      \n",
      "     |      :param c5: If true, then the tags used will be the more detailed\n",
      "     |          c5 tags.  Otherwise, the simplified tags will be used.\n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, c5=False, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |      \n",
      "     |      :param c5: If true, then the tags used will be the more detailed\n",
      "     |          c5 tags.  Otherwise, the simplified tags will be used.\n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  words(self, fileids=None, strip_space=True, stem=False)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |      \n",
      "     |      :param strip_space: If true, then strip trailing spaces from\n",
      "     |          word tokens.  Otherwise, leave the spaces on the tokens.\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class BracketParseCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  BracketParseCorpusReader(root, fileids, comment_char=None, detect_blocks='unindented_paren', encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for corpora that consist of parenthesis-delineated parse trees,\n",
      "     |  like those found in the \"combined\" section of the Penn Treebank,\n",
      "     |  e.g. \"(S (NP (DT the) (JJ little) (NN dog)) (VP (VBD barked)))\".\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, comment_char=None, detect_blocks='unindented_paren', encoding='utf8', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param comment_char: The character which can appear at the start of\n",
      "     |          a line to indicate that the rest of the line is a comment.\n",
      "     |      :param detect_blocks: The method that is used to find blocks\n",
      "     |        in the corpus; can be 'unindented_paren' (every unindented\n",
      "     |        parenthesis starts a new parse) or 'sexpr' (brackets are\n",
      "     |        matched).\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CHILDESCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  CHILDESCorpusReader(root, fileids, lazy=True)\n",
      "     |  \n",
      "     |  Corpus reader for the XML version of the CHILDES corpus.\n",
      "     |  The CHILDES corpus is available at ``https://childes.talkbank.org/``. The XML\n",
      "     |  version of CHILDES is located at ``https://childes.talkbank.org/data-xml/``.\n",
      "     |  Copy the needed parts of the CHILDES XML corpus into the NLTK data directory\n",
      "     |  (``nltk_data/corpora/CHILDES/``).\n",
      "     |  \n",
      "     |  For access to the file text use the usual nltk functions,\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()`` and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CHILDESCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  MLU(self, fileids=None, speaker='CHI')\n",
      "     |      :return: the given file(s) as a floating number\n",
      "     |      :rtype: list(float)\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  age(self, fileids=None, speaker='CHI', month=False)\n",
      "     |      :return: the given file(s) as string or int\n",
      "     |      :rtype: list or int\n",
      "     |      \n",
      "     |      :param month: If true, return months instead of year-month-date\n",
      "     |  \n",
      "     |  convert_age(self, age_year)\n",
      "     |      Caclculate age in months from a string in CHILDES format\n",
      "     |  \n",
      "     |  corpus(self, fileids=None)\n",
      "     |      :return: the given file(s) as a dict of ``(corpus_property_key, value)``\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  participants(self, fileids=None)\n",
      "     |      :return: the given file(s) as a dict of\n",
      "     |          ``(participant_property_key, value)``\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, speaker='ALL', stem=False, relation=None, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |          encoded as a list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of ``(str,pos,relation_list)``.\n",
      "     |          If there is manually-annotated relation info, it will return\n",
      "     |          tuples of ``(str,pos,test_relation_list,str,pos,gold_relation_list)``\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, speaker='ALL', stem=False, relation=None, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of ``(str,pos,relation_list)``.\n",
      "     |          If there is manually-annotated relation info, it will return\n",
      "     |          tuples of ``(str,pos,test_relation_list,str,pos,gold_relation_list)``\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, speaker='ALL', stem=False, relation=False, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of (stem, index,\n",
      "     |          dependent_index)\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  webview_file(self, fileid, urlbase=None)\n",
      "     |      Map a corpus file to its web version on the CHILDES website,\n",
      "     |      and open it in a web browser.\n",
      "     |      \n",
      "     |      The complete URL to be used is:\n",
      "     |          childes.childes_url_base + urlbase + fileid.replace('.xml', '.cha')\n",
      "     |      \n",
      "     |      If no urlbase is passed, we try to calculate it.  This\n",
      "     |      requires that the childes corpus was set up to mirror the\n",
      "     |      folder hierarchy under childes.psy.cmu.edu/data-xml/, e.g.:\n",
      "     |      nltk_data/corpora/childes/Eng-USA/Cornell/??? or\n",
      "     |      nltk_data/corpora/childes/Romance/Spanish/Aguirre/???\n",
      "     |      \n",
      "     |      The function first looks (as a special case) if \"Eng-USA\" is\n",
      "     |      on the path consisting of <corpus root>+fileid; then if\n",
      "     |      \"childes\", possibly followed by \"data-xml\", appears. If neither\n",
      "     |      one is found, we use the unmodified fileid and hope for the best.\n",
      "     |      If this is not right, specify urlbase explicitly, e.g., if the\n",
      "     |      corpus root points to the Cornell folder, urlbase='Eng-USA/Cornell'.\n",
      "     |  \n",
      "     |  words(self, fileids=None, speaker='ALL', stem=False, relation=False, strip_space=True, replace=False)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |      :rtype: list(str)\n",
      "     |      \n",
      "     |      :param speaker: If specified, select specific speaker(s) defined\n",
      "     |          in the corpus. Default is 'ALL' (all participants). Common choices\n",
      "     |          are 'CHI' (the child), 'MOT' (mother), ['CHI','MOT'] (exclude\n",
      "     |          researchers)\n",
      "     |      :param stem: If true, then use word stems instead of word strings.\n",
      "     |      :param relation: If true, then return tuples of (stem, index,\n",
      "     |          dependent_index)\n",
      "     |      :param strip_space: If true, then strip trailing spaces from word\n",
      "     |          tokens. Otherwise, leave the spaces on the tokens.\n",
      "     |      :param replace: If true, then use the replaced (intended) word instead\n",
      "     |          of the original word (e.g., 'wat' will be replaced with 'watch')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  childes_url_base = 'https://childes.talkbank.org/browser/index.php?url...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CMUDictCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  CMUDictCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CMUDictCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  dict(self)\n",
      "     |      :return: the cmudict lexicon as a dictionary, whose keys are\n",
      "     |      lowercase words and whose values are lists of pronunciations.\n",
      "     |  \n",
      "     |  entries(self)\n",
      "     |      :return: the cmudict lexicon as a list of entries\n",
      "     |      containing (word, transcriptions) tuples.\n",
      "     |  \n",
      "     |  raw(self)\n",
      "     |      :return: the cmudict lexicon as a raw string.\n",
      "     |  \n",
      "     |  words(self)\n",
      "     |      :return: a list of all words defined in the cmudict lexicon.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedBracketParseCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, BracketParseCorpusReader)\n",
      "     |  CategorizedBracketParseCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A reader for parsed corpora whose documents are\n",
      "     |  divided into categories based on their file identifiers.\n",
      "     |  @author: Nathan Schneider <nschneid@cs.cmu.edu>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedBracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      BracketParseCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (C{cat_pattern}, C{cat_map}, and C{cat_file}) are passed to\n",
      "     |      the L{CategorizedCorpusReader constructor\n",
      "     |      <CategorizedCorpusReader.__init__>}.  The remaining arguments\n",
      "     |      are passed to the L{BracketParseCorpusReader constructor\n",
      "     |      <BracketParseCorpusReader.__init__>}.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_paras(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  parsed_words(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedCorpusReader(builtins.object)\n",
      "     |  CategorizedCorpusReader(kwargs)\n",
      "     |  \n",
      "     |  A mixin class used to aid in the implementation of corpus readers\n",
      "     |  for categorized corpora.  This class defines the method\n",
      "     |  ``categories()``, which returns a list of the categories for the\n",
      "     |  corpus or for a specified set of fileids; and overrides ``fileids()``\n",
      "     |  to take a ``categories`` argument, restricting the set of fileids to\n",
      "     |  be returned.\n",
      "     |  \n",
      "     |  Subclasses are expected to:\n",
      "     |  \n",
      "     |    - Call ``__init__()`` to set up the mapping.\n",
      "     |  \n",
      "     |    - Override all view methods to accept a ``categories`` parameter,\n",
      "     |      which can be used *instead* of the ``fileids`` parameter, to\n",
      "     |      select which fileids should be included in the returned view.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, kwargs)\n",
      "     |      Initialize this mapping based on keyword arguments, as\n",
      "     |      follows:\n",
      "     |      \n",
      "     |        - cat_pattern: A regular expression pattern used to find the\n",
      "     |          category for each file identifier.  The pattern will be\n",
      "     |          applied to each file identifier, and the first matching\n",
      "     |          group will be used as the category label for that file.\n",
      "     |      \n",
      "     |        - cat_map: A dictionary, mapping from file identifiers to\n",
      "     |          category labels.\n",
      "     |      \n",
      "     |        - cat_file: The name of a file that contains the mapping\n",
      "     |          from file identifiers to categories.  The argument\n",
      "     |          ``cat_delimiter`` can be used to specify a delimiter.\n",
      "     |      \n",
      "     |      The corresponding argument will be deleted from ``kwargs``.  If\n",
      "     |      more than one argument is specified, an exception will be\n",
      "     |      raised.\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class CategorizedPlaintextCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, PlaintextCorpusReader)\n",
      "     |  CategorizedPlaintextCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A reader for plaintext corpora whose documents are divided into\n",
      "     |  categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedPlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``PlaintextCorpusReader`` constructor.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedSentencesCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "     |  CategorizedSentencesCorpusReader(root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8', **kwargs)\n",
      "     |  \n",
      "     |  A reader for corpora in which each row represents a single instance, mainly\n",
      "     |  a sentence. Istances are divided into categories based on their file identifiers\n",
      "     |  (see CategorizedCorpusReader).\n",
      "     |  Since many corpora allow rows that contain more than one sentence, it is\n",
      "     |  possible to specify a sentence tokenizer to retrieve all sentences instead\n",
      "     |  than all rows.\n",
      "     |  \n",
      "     |  Examples using the Subjectivity Dataset:\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import subjectivity\n",
      "     |  >>> subjectivity.sents()[23]\n",
      "     |  ['television', 'made', 'him', 'famous', ',', 'but', 'his', 'biggest', 'hits',\n",
      "     |  'happened', 'off', 'screen', '.']\n",
      "     |  >>> subjectivity.categories()\n",
      "     |  ['obj', 'subj']\n",
      "     |  >>> subjectivity.words(categories='subj')\n",
      "     |  ['smart', 'and', 'alert', ',', 'thirteen', ...]\n",
      "     |  \n",
      "     |  Examples using the Sentence Polarity Dataset:\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import sentence_polarity\n",
      "     |  >>> sentence_polarity.sents()\n",
      "     |  [['simplistic', ',', 'silly', 'and', 'tedious', '.'], [\"it's\", 'so', 'laddish',\n",
      "     |  'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find',\n",
      "     |  'it', 'funny', '.'], ...]\n",
      "     |  >>> sentence_polarity.categories()\n",
      "     |  ['neg', 'pos']\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedSentencesCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8', **kwargs)\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param sent_tokenizer: a tokenizer for breaking paragraphs into sentences.\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |      :param kwargs: additional parameters passed to CategorizedCorpusReader.\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids that have to be\n",
      "     |          returned as a raw string.\n",
      "     |      :param categories: a list specifying the categories whose files have to\n",
      "     |          be returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus Readme.txt file.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      Return all sentences in the corpus or in the specified file(s).\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose sentences have\n",
      "     |          to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences.\n",
      "     |          Each sentence is tokenized using the specified word_tokenizer.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      file(s).\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose words have to\n",
      "     |          be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CategorizedTaggedCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, TaggedCorpusReader)\n",
      "     |  CategorizedTaggedCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A reader for part-of-speech tagged corpora whose documents are\n",
      "     |  divided into categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategorizedTaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``TaggedCorpusReader``.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ChasenCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ChasenCorpusReader(root, fileids, encoding='utf8', sent_splitter=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChasenCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', sent_splitter=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ChunkedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ChunkedCorpusReader(root, fileids, extension='', str2chunktree=<function tagstr2tree at 0x00000207D8A47948>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x00000207D8B81558>, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for chunked (and optionally tagged) corpora.  Paragraphs\n",
      "     |  are split using a block reader.  They are then tokenized into\n",
      "     |  sentences using a sentence tokenizer.  Finally, these sentences\n",
      "     |  are parsed into chunk trees using a string-to-chunktree conversion\n",
      "     |  function.  Each of these steps can be performed using a default\n",
      "     |  function or a custom function.  By default, paragraphs are split\n",
      "     |  on blank lines; sentences are listed one per line; and sentences\n",
      "     |  are parsed into chunk trees using ``nltk.chunk.tagstr2tree``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChunkedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, extension='', str2chunktree=<function tagstr2tree at 0x00000207D8A47948>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x00000207D8B81558>, encoding='utf8', tagset=None)\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  chunked_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as a shallow Tree.  The leaves of these\n",
      "     |          trees are encoded as ``(word, tag)`` tuples (if the corpus\n",
      "     |          has tags) or word strings (if the corpus has no tags).\n",
      "     |      :rtype: list(list(Tree))\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a shallow Tree.  The leaves\n",
      "     |          of these trees are encoded as ``(word, tag)`` tuples (if\n",
      "     |          the corpus has tags) or word strings (if the corpus has no\n",
      "     |          tags).\n",
      "     |      :rtype: list(Tree)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and chunks.  Words are encoded as ``(word, tag)``\n",
      "     |          tuples (if the corpus has tags) or word strings (if the\n",
      "     |          corpus has no tags).  Chunks are encoded as depth-one\n",
      "     |          trees over ``(word,tag)`` tuples or word strings.\n",
      "     |      :rtype: list(tuple(str,str) and Tree)\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ComparativeSentencesCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ComparativeSentencesCorpusReader(root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for the Comparative Sentence Dataset by Jindal and Liu (2006).\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import comparative_sentences\n",
      "     |      >>> comparison = comparative_sentences.comparisons()[0]\n",
      "     |      >>> comparison.text\n",
      "     |      ['its', 'fast-forward', 'and', 'rewind', 'work', 'much', 'more', 'smoothly',\n",
      "     |      'and', 'consistently', 'than', 'those', 'of', 'other', 'models', 'i', \"'ve\",\n",
      "     |      'had', '.']\n",
      "     |      >>> comparison.entity_2\n",
      "     |      'models'\n",
      "     |      >>> (comparison.feature, comparison.keyword)\n",
      "     |      ('rewind', 'more')\n",
      "     |      >>> len(comparative_sentences.comparisons())\n",
      "     |      853\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ComparativeSentencesCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param sent_tokenizer: tokenizer for breaking paragraphs into sentences.\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |  \n",
      "     |  comparisons(self, fileids=None)\n",
      "     |      Return all comparisons in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          comparisons have to be returned.\n",
      "     |      :return: the given file(s) as a list of Comparison objects.\n",
      "     |      :rtype: list(Comparison)\n",
      "     |  \n",
      "     |  keywords(self, fileids=None)\n",
      "     |      Return a set of all keywords used in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          keywords have to be returned.\n",
      "     |      :return: the set of keywords and comparative phrases used in the corpus.\n",
      "     |      :rtype: set(str)\n",
      "     |  \n",
      "     |  keywords_readme(self)\n",
      "     |      Return the list of words and constituents considered as clues of a\n",
      "     |      comparison (from listOfkeywords.txt).\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids that have to be\n",
      "     |          returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus readme file.\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      Return all sentences in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :return: all sentences of the corpus as lists of tokens (or as plain\n",
      "     |          strings, if no word tokenizer is specified).\n",
      "     |      :rtype: list(list(str)) or list(str)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words and punctuation symbols in the corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ConllChunkCorpusReader(ConllCorpusReader)\n",
      "     |  ConllChunkCorpusReader(root, fileids, chunk_types, encoding='utf8', tagset=None, separator=None)\n",
      "     |  \n",
      "     |  A ConllCorpusReader whose data file contains three columns: words,\n",
      "     |  pos, and chunk.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConllChunkCorpusReader\n",
      "     |      ConllCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, chunk_types, encoding='utf8', tagset=None, separator=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ConllCorpusReader:\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  iob_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of lists of word/tag/IOB tuples\n",
      "     |      :rtype: list(list)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  iob_words(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of word/tag/IOB tuples\n",
      "     |      :rtype: list(tuple)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, pos_in_tree=None, tagset=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  srl_instances(self, fileids=None, pos_in_tree=None, flatten=True)\n",
      "     |  \n",
      "     |  srl_spans(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from ConllCorpusReader:\n",
      "     |  \n",
      "     |  CHUNK = 'chunk'\n",
      "     |  \n",
      "     |  COLUMN_TYPES = ('words', 'pos', 'tree', 'chunk', 'ne', 'srl', 'ignore'...\n",
      "     |  \n",
      "     |  IGNORE = 'ignore'\n",
      "     |  \n",
      "     |  NE = 'ne'\n",
      "     |  \n",
      "     |  POS = 'pos'\n",
      "     |  \n",
      "     |  SRL = 'srl'\n",
      "     |  \n",
      "     |  TREE = 'tree'\n",
      "     |  \n",
      "     |  WORDS = 'words'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ConllCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ConllCorpusReader(root, fileids, columntypes, chunk_types=None, root_label='S', pos_in_tree=False, srl_includes_roleset=True, encoding='utf8', tree_class=<class 'nltk.tree.Tree'>, tagset=None, separator=None)\n",
      "     |  \n",
      "     |  A corpus reader for CoNLL-style files.  These files consist of a\n",
      "     |  series of sentences, separated by blank lines.  Each sentence is\n",
      "     |  encoded using a table (or \"grid\") of values, where each line\n",
      "     |  corresponds to a single word, and each column corresponds to an\n",
      "     |  annotation type.  The set of columns used by CoNLL-style files can\n",
      "     |  vary from corpus to corpus; the ``ConllCorpusReader`` constructor\n",
      "     |  therefore takes an argument, ``columntypes``, which is used to\n",
      "     |  specify the columns that are used by a given corpus. By default\n",
      "     |  columns are split by consecutive whitespaces, with the\n",
      "     |  ``separator`` argument you can set a string to split by (e.g.\n",
      "     |  ``' '``).\n",
      "     |  \n",
      "     |  \n",
      "     |  @todo: Add support for reading from corpora where different\n",
      "     |      parallel files contain different columns.\n",
      "     |  @todo: Possibly add caching of the grid corpus view?  This would\n",
      "     |      allow the same grid view to be used by different data access\n",
      "     |      methods (eg words() and parsed_sents() could both share the\n",
      "     |      same grid corpus view object).\n",
      "     |  @todo: Better support for -DOCSTART-.  Currently, we just ignore\n",
      "     |      it, but it could be used to define methods that retrieve a\n",
      "     |      document at a time (eg parsed_documents()).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConllCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, columntypes, chunk_types=None, root_label='S', pos_in_tree=False, srl_includes_roleset=True, encoding='utf8', tree_class=<class 'nltk.tree.Tree'>, tagset=None, separator=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  chunked_sents(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  chunked_words(self, fileids=None, chunk_types=None, tagset=None)\n",
      "     |  \n",
      "     |  iob_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of lists of word/tag/IOB tuples\n",
      "     |      :rtype: list(list)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  iob_words(self, fileids=None, tagset=None)\n",
      "     |      :return: a list of word/tag/IOB tuples\n",
      "     |      :rtype: list(tuple)\n",
      "     |      :param fileids: the list of fileids that make up this corpus\n",
      "     |      :type fileids: None or str or list\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None, pos_in_tree=None, tagset=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  srl_instances(self, fileids=None, pos_in_tree=None, flatten=True)\n",
      "     |  \n",
      "     |  srl_spans(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CHUNK = 'chunk'\n",
      "     |  \n",
      "     |  COLUMN_TYPES = ('words', 'pos', 'tree', 'chunk', 'ne', 'srl', 'ignore'...\n",
      "     |  \n",
      "     |  IGNORE = 'ignore'\n",
      "     |  \n",
      "     |  NE = 'ne'\n",
      "     |  \n",
      "     |  POS = 'pos'\n",
      "     |  \n",
      "     |  SRL = 'srl'\n",
      "     |  \n",
      "     |  TREE = 'tree'\n",
      "     |  \n",
      "     |  WORDS = 'words'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CorpusReader(builtins.object)\n",
      "     |  CorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class CrubadanCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  CrubadanCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A corpus reader used to access language An Crubadan n-gram files.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CrubadanCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  crubadan_to_iso(self, lang)\n",
      "     |      Return ISO 639-3 code given internal Crubadan code\n",
      "     |  \n",
      "     |  iso_to_crubadan(self, lang)\n",
      "     |      Return internal Crubadan code based on ISO 639-3 code\n",
      "     |  \n",
      "     |  lang_freq(self, lang)\n",
      "     |      Return n-gram FreqDist for a specific language\n",
      "     |      given ISO 639-3 language code\n",
      "     |  \n",
      "     |  langs(self)\n",
      "     |      Return a list of supported languages as ISO 639-3 codes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class DependencyCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  DependencyCorpusReader(root, fileids, encoding='utf8', word_tokenizer=<nltk.tokenize.simple.TabTokenizer object at 0x00000207D8C45C08>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x00000207D8B81558>)\n",
      "     |  \n",
      "     |  An abstract base class for reading corpora consisting of\n",
      "     |  syntactically parsed text.  Subclasses should define:\n",
      "     |  \n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DependencyCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', word_tokenizer=<nltk.tokenize.simple.TabTokenizer object at 0x00000207D8C45C08>, sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x00000207D8B81558>)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class EuroparlCorpusReader(PlaintextCorpusReader)\n",
      "     |  EuroparlCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x00000207D8B75108>, para_block_reader=<function read_blankline_block at 0x00000207D8B81558>, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for Europarl corpora that consist of plaintext documents.\n",
      "     |  Documents are divided into chapters instead of paragraphs as\n",
      "     |  for regular plaintext documents. Chapters are separated using blank\n",
      "     |  lines. Everything is inherited from ``PlaintextCorpusReader`` except\n",
      "     |  that:\n",
      "     |    - Since the corpus is pre-processed and pre-tokenized, the\n",
      "     |      word tokenizer should just split the line at whitespaces.\n",
      "     |    - For the same reason, the sentence tokenizer should just\n",
      "     |      split the paragraph at line breaks.\n",
      "     |    - There is a new 'chapters()' method that returns chapters instead\n",
      "     |      instead of paragraphs.\n",
      "     |    - The 'paras()' method inherited from PlaintextCorpusReader is\n",
      "     |      made non-functional to remove any confusion between chapters\n",
      "     |      and paragraphs for Europarl.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EuroparlCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  chapters(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          chapters, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x00000207D8B75108>, para_block_reader=<function read_blankline_block at 0x00000207D8B81558>, encoding='utf8')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class FramenetCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  FramenetCorpusReader(root, fileids)\n",
      "     |  \n",
      "     |  A corpus reader for the Framenet Corpus.\n",
      "     |  \n",
      "     |  >>> from nltk.corpus import framenet as fn\n",
      "     |  >>> fn.lu(3238).frame.lexUnit['glint.v'] is fn.lu(3238)\n",
      "     |  True\n",
      "     |  >>> fn.frame_by_name('Replacing') is fn.lus('replace.v')[0].frame\n",
      "     |  True\n",
      "     |  >>> fn.lus('prejudice.n')[0].frame.frameRelations == fn.frame_relations('Partiality')\n",
      "     |  True\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FramenetCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  annotations(self, luNamePattern=None, exemplars=True, full_text=True)\n",
      "     |      Frame annotation sets matching the specified criteria.\n",
      "     |  \n",
      "     |  buildindexes(self)\n",
      "     |      Build the internal indexes to make look-ups faster.\n",
      "     |  \n",
      "     |  doc(self, fn_docid)\n",
      "     |      Returns the annotated document whose id number is\n",
      "     |      ``fn_docid``. This id number can be obtained by calling the\n",
      "     |      Documents() function.\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain the\n",
      "     |      following keys:\n",
      "     |      \n",
      "     |      - '_type'      : 'fulltextannotation'\n",
      "     |      - 'sentence'   : a list of sentences in the document\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'ID'    : the ID number of the sentence\n",
      "     |            - '_type' : 'sentence'\n",
      "     |            - 'text'  : the text of the sentence\n",
      "     |            - 'paragNo' : the paragraph number\n",
      "     |            - 'sentNo'  : the sentence number\n",
      "     |            - 'docID'   : the document ID number\n",
      "     |            - 'corpID'  : the corpus ID number\n",
      "     |            - 'aPos'    : the annotation position\n",
      "     |            - 'annotationSet' : a list of annotation layers for the sentence\n",
      "     |               - Each item in the list is a dict containing the following keys:\n",
      "     |                  - 'ID'       : the ID number of the annotation set\n",
      "     |                  - '_type'    : 'annotationset'\n",
      "     |                  - 'status'   : either 'MANUAL' or 'UNANN'\n",
      "     |                  - 'luName'   : (only if status is 'MANUAL')\n",
      "     |                  - 'luID'     : (only if status is 'MANUAL')\n",
      "     |                  - 'frameID'  : (only if status is 'MANUAL')\n",
      "     |                  - 'frameName': (only if status is 'MANUAL')\n",
      "     |                  - 'layer' : a list of labels for the layer\n",
      "     |                     - Each item in the layer is a dict containing the\n",
      "     |                       following keys:\n",
      "     |                        - '_type': 'layer'\n",
      "     |                        - 'rank'\n",
      "     |                        - 'name'\n",
      "     |                        - 'label' : a list of labels in the layer\n",
      "     |                           - Each item is a dict containing the following keys:\n",
      "     |                              - 'start'\n",
      "     |                              - 'end'\n",
      "     |                              - 'name'\n",
      "     |                              - 'feID' (optional)\n",
      "     |      \n",
      "     |      :param fn_docid: The Framenet id number of the document\n",
      "     |      :type fn_docid: int\n",
      "     |      :return: Information about the annotated document\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  docs(self, name=None)\n",
      "     |      Return a list of the annotated full-text documents in FrameNet,\n",
      "     |      optionally filtered by a regex to be matched against the document name.\n",
      "     |  \n",
      "     |  docs_metadata(self, name=None)\n",
      "     |      Return an index of the annotated documents in Framenet.\n",
      "     |      \n",
      "     |      Details for a specific annotated document can be obtained using this\n",
      "     |      class's doc() function and pass it the value of the 'ID' field.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.docs()) in (78, 107) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> set([x.corpname for x in fn.docs_metadata()])>=set(['ANC', 'KBEval',                     'LUCorpus-v0.3', 'Miscellaneous', 'NTI', 'PropBank'])\n",
      "     |      True\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to search the\n",
      "     |          file name of each annotated document. The document's\n",
      "     |          file name contains the name of the corpus that the\n",
      "     |          document is from, followed by two underscores \"__\"\n",
      "     |          followed by the document name. So, for example, the\n",
      "     |          file name \"LUCorpus-v0.3__20000410_nyt-NEW.xml\" is\n",
      "     |          from the corpus named \"LUCorpus-v0.3\" and the\n",
      "     |          document name is \"20000410_nyt-NEW.xml\".\n",
      "     |      :type name: str\n",
      "     |      :return: A list of selected (or all) annotated documents\n",
      "     |      :rtype: list of dicts, where each dict object contains the following\n",
      "     |              keys:\n",
      "     |      \n",
      "     |              - 'name'\n",
      "     |              - 'ID'\n",
      "     |              - 'corpid'\n",
      "     |              - 'corpname'\n",
      "     |              - 'description'\n",
      "     |              - 'filename'\n",
      "     |  \n",
      "     |  exemplars(self, luNamePattern=None, frame=None, fe=None, fe2=None)\n",
      "     |      Lexicographic exemplar sentences, optionally filtered by LU name and/or 1-2 FEs that\n",
      "     |      are realized overtly. 'frame' may be a name pattern, frame ID, or frame instance.\n",
      "     |      'fe' may be a name pattern or FE instance; if specified, 'fe2' may also\n",
      "     |      be specified to retrieve sentences with both overt FEs (in either order).\n",
      "     |  \n",
      "     |  fe_relations(self)\n",
      "     |      Obtain a list of frame element relations.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> ferels = fn.fe_relations()\n",
      "     |      >>> isinstance(ferels, list)\n",
      "     |      True\n",
      "     |      >>> len(ferels) in (10020, 12393)   # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyDict(ferels[0], breakLines=True)\n",
      "     |      {'ID': 14642,\n",
      "     |      '_type': 'ferelation',\n",
      "     |      'frameRelation': <Parent=Abounding_with -- Inheritance -> Child=Lively_place>,\n",
      "     |      'subFE': <fe ID=11370 name=Degree>,\n",
      "     |      'subFEName': 'Degree',\n",
      "     |      'subFrame': <frame ID=1904 name=Lively_place>,\n",
      "     |      'subID': 11370,\n",
      "     |      'supID': 2271,\n",
      "     |      'superFE': <fe ID=2271 name=Degree>,\n",
      "     |      'superFEName': 'Degree',\n",
      "     |      'superFrame': <frame ID=262 name=Abounding_with>,\n",
      "     |      'type': <framerelationtype ID=1 name=Inheritance>}\n",
      "     |      \n",
      "     |      :return: A list of all of the frame element relations in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  fes(self, name=None, frame=None)\n",
      "     |      Lists frame element objects. If 'name' is provided, this is treated as\n",
      "     |      a case-insensitive regular expression to filter by frame name.\n",
      "     |      (Case-insensitivity is because casing of frame element names is not always\n",
      "     |      consistent across frames.) Specify 'frame' to filter by a frame name pattern,\n",
      "     |      ID, or object.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.fes('Noise_maker')\n",
      "     |      [<fe ID=6043 name=Noise_maker>]\n",
      "     |      >>> sorted([(fe.frame.name,fe.name) for fe in fn.fes('sound')])\n",
      "     |      [('Cause_to_make_noise', 'Sound_maker'), ('Make_noise', 'Sound'),\n",
      "     |       ('Make_noise', 'Sound_source'), ('Sound_movement', 'Location_of_sound_source'),\n",
      "     |       ('Sound_movement', 'Sound'), ('Sound_movement', 'Sound_source'),\n",
      "     |       ('Sounds', 'Component_sound'), ('Sounds', 'Location_of_sound_source'),\n",
      "     |       ('Sounds', 'Sound_source'), ('Vocalizations', 'Location_of_sound_source'),\n",
      "     |       ('Vocalizations', 'Sound_source')]\n",
      "     |      >>> sorted([(fe.frame.name,fe.name) for fe in fn.fes('sound',r'(?i)make_noise')])\n",
      "     |      [('Cause_to_make_noise', 'Sound_maker'),\n",
      "     |       ('Make_noise', 'Sound'),\n",
      "     |       ('Make_noise', 'Sound_source')]\n",
      "     |      >>> sorted(set(fe.name for fe in fn.fes('^sound')))\n",
      "     |      ['Sound', 'Sound_maker', 'Sound_source']\n",
      "     |      >>> len(fn.fes('^sound$'))\n",
      "     |      2\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to match against\n",
      "     |          frame element names. If 'name' is None, then a list of all\n",
      "     |          frame elements will be returned.\n",
      "     |      :type name: str\n",
      "     |      :return: A list of matching frame elements\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  frame(self, fn_fid_or_fname, ignorekeys=[])\n",
      "     |      Get the details for the specified Frame using the frame's name\n",
      "     |      or id number.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame(256)\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f = fn.frame('Medical_specialties')\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> # ensure non-ASCII character in definition doesn't trigger an encoding error:\n",
      "     |      >>> fn.frame('Imposing_obligation')\n",
      "     |      frame (1494): Imposing_obligation...\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain the\n",
      "     |      following information about the Frame:\n",
      "     |      \n",
      "     |      - 'name'       : the name of the Frame (e.g. 'Birth', 'Apply_heat', etc.)\n",
      "     |      - 'definition' : textual definition of the Frame\n",
      "     |      - 'ID'         : the internal ID number of the Frame\n",
      "     |      - 'semTypes'   : a list of semantic types for this frame\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'name' : can be used with the semtype() function\n",
      "     |            - 'ID'   : can be used with the semtype() function\n",
      "     |      \n",
      "     |      - 'lexUnit'    : a dict containing all of the LUs for this frame.\n",
      "     |                       The keys in this dict are the names of the LUs and\n",
      "     |                       the value for each key is itself a dict containing\n",
      "     |                       info about the LU (see the lu() function for more info.)\n",
      "     |      \n",
      "     |      - 'FE' : a dict containing the Frame Elements that are part of this frame\n",
      "     |               The keys in this dict are the names of the FEs (e.g. 'Body_system')\n",
      "     |               and the values are dicts containing the following keys\n",
      "     |            - 'definition' : The definition of the FE\n",
      "     |            - 'name'       : The name of the FE e.g. 'Body_system'\n",
      "     |            - 'ID'         : The id number\n",
      "     |            - '_type'      : 'fe'\n",
      "     |            - 'abbrev'     : Abbreviation e.g. 'bod'\n",
      "     |            - 'coreType'   : one of \"Core\", \"Peripheral\", or \"Extra-Thematic\"\n",
      "     |            - 'semType'    : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : name of the semantic type. can be used with\n",
      "     |                          the semtype() function\n",
      "     |               - 'ID'   : id number of the semantic type. can be used with\n",
      "     |                          the semtype() function\n",
      "     |            - 'requiresFE' : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : the name of another FE in this frame\n",
      "     |               - 'ID'   : the id of the other FE in this frame\n",
      "     |            - 'excludesFE' : if not None, a dict with the following two keys:\n",
      "     |               - 'name' : the name of another FE in this frame\n",
      "     |               - 'ID'   : the id of the other FE in this frame\n",
      "     |      \n",
      "     |      - 'frameRelation'      : a list of objects describing frame relations\n",
      "     |      - 'FEcoreSets'  : a list of Frame Element core sets for this frame\n",
      "     |         - Each item in the list is a list of FE objects\n",
      "     |      \n",
      "     |      :param fn_fid_or_fname: The Framenet name or id number of the frame\n",
      "     |      :type fn_fid_or_fname: int or str\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  frame_by_id(self, fn_fid, ignorekeys=[])\n",
      "     |      Get the details for the specified Frame using the frame's id\n",
      "     |      number.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame_by_id(256)\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f.definition\n",
      "     |      \"This frame includes words that name ...\"\n",
      "     |      \n",
      "     |      :param fn_fid: The Framenet id number of the frame\n",
      "     |      :type fn_fid: int\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |      \n",
      "     |      Also see the ``frame()`` function for details about what is\n",
      "     |      contained in the dict that is returned.\n",
      "     |  \n",
      "     |  frame_by_name(self, fn_fname, ignorekeys=[], check_cache=True)\n",
      "     |      Get the details for the specified Frame using the frame's name.\n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> f = fn.frame_by_name('Medical_specialties')\n",
      "     |      >>> f.ID\n",
      "     |      256\n",
      "     |      >>> f.name\n",
      "     |      'Medical_specialties'\n",
      "     |      >>> f.definition\n",
      "     |      \"This frame includes words that name ...\"\n",
      "     |      \n",
      "     |      :param fn_fname: The name of the frame\n",
      "     |      :type fn_fname: str\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: Information about a frame\n",
      "     |      :rtype: dict\n",
      "     |      \n",
      "     |      Also see the ``frame()`` function for details about what is\n",
      "     |      contained in the dict that is returned.\n",
      "     |  \n",
      "     |  frame_ids_and_names(self, name=None)\n",
      "     |      Uses the frame index, which is much faster than looking up each frame definition\n",
      "     |      if only the names and IDs are needed.\n",
      "     |  \n",
      "     |  frame_relation_types(self)\n",
      "     |      Obtain a list of frame relation types.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> frts = sorted(fn.frame_relation_types(), key=itemgetter('ID'))\n",
      "     |      >>> isinstance(frts, list)\n",
      "     |      True\n",
      "     |      >>> len(frts) in (9, 10)    # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyDict(frts[0], breakLines=True)\n",
      "     |      {'ID': 1,\n",
      "     |       '_type': 'framerelationtype',\n",
      "     |       'frameRelations': [<Parent=Event -- Inheritance -> Child=Change_of_consistency>, <Parent=Event -- Inheritance -> Child=Rotting>, ...],\n",
      "     |       'name': 'Inheritance',\n",
      "     |       'subFrameName': 'Child',\n",
      "     |       'superFrameName': 'Parent'}\n",
      "     |      \n",
      "     |      :return: A list of all of the frame relation types in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  frame_relations(self, frame=None, frame2=None, type=None)\n",
      "     |      :param frame: (optional) frame object, name, or ID; only relations involving\n",
      "     |      this frame will be returned\n",
      "     |      :param frame2: (optional; 'frame' must be a different frame) only show relations\n",
      "     |      between the two specified frames, in either direction\n",
      "     |      :param type: (optional) frame relation type (name or object); show only relations\n",
      "     |      of this type\n",
      "     |      :type frame: int or str or AttrDict\n",
      "     |      :return: A list of all of the frame relations in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> frels = fn.frame_relations()\n",
      "     |      >>> isinstance(frels, list)\n",
      "     |      True\n",
      "     |      >>> len(frels) in (1676, 2070)  # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation'), maxReprSize=0, breakLines=True)\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>,\n",
      "     |       <Parent=Apply_heat -- Using -> Child=Cooking_creation>,\n",
      "     |       <MainEntry=Apply_heat -- See_also -> ReferringEntry=Cooking_creation>]\n",
      "     |      >>> PrettyList(fn.frame_relations(274), breakLines=True)\n",
      "     |      [<Parent=Avoiding -- Inheritance -> Child=Dodging>,\n",
      "     |       <Parent=Avoiding -- Inheritance -> Child=Evading>, ...]\n",
      "     |      >>> PrettyList(fn.frame_relations(fn.frame('Cooking_creation')), breakLines=True)\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>,\n",
      "     |       <Parent=Apply_heat -- Using -> Child=Cooking_creation>, ...]\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation', type='Inheritance'))\n",
      "     |      [<Parent=Intentionally_create -- Inheritance -> Child=Cooking_creation>]\n",
      "     |      >>> PrettyList(fn.frame_relations('Cooking_creation', 'Apply_heat'), breakLines=True)\n",
      "     |      [<Parent=Apply_heat -- Using -> Child=Cooking_creation>,\n",
      "     |      <MainEntry=Apply_heat -- See_also -> ReferringEntry=Cooking_creation>]\n",
      "     |  \n",
      "     |  frames(self, name=None)\n",
      "     |      Obtain details for a specific frame.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.frames()) in (1019, 1221)    # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> x = PrettyList(fn.frames(r'(?i)crim'), maxReprSize=0, breakLines=True)\n",
      "     |      >>> x.sort(key=itemgetter('ID'))\n",
      "     |      >>> x\n",
      "     |      [<frame ID=200 name=Criminal_process>,\n",
      "     |       <frame ID=500 name=Criminal_investigation>,\n",
      "     |       <frame ID=692 name=Crime_scenario>,\n",
      "     |       <frame ID=700 name=Committing_crime>]\n",
      "     |      \n",
      "     |      A brief intro to Frames (excerpted from \"FrameNet II: Extended\n",
      "     |      Theory and Practice\" by Ruppenhofer et. al., 2010):\n",
      "     |      \n",
      "     |      A Frame is a script-like conceptual structure that describes a\n",
      "     |      particular type of situation, object, or event along with the\n",
      "     |      participants and props that are needed for that Frame. For\n",
      "     |      example, the \"Apply_heat\" frame describes a common situation\n",
      "     |      involving a Cook, some Food, and a Heating_Instrument, and is\n",
      "     |      evoked by words such as bake, blanch, boil, broil, brown,\n",
      "     |      simmer, steam, etc.\n",
      "     |      \n",
      "     |      We call the roles of a Frame \"frame elements\" (FEs) and the\n",
      "     |      frame-evoking words are called \"lexical units\" (LUs).\n",
      "     |      \n",
      "     |      FrameNet includes relations between Frames. Several types of\n",
      "     |      relations are defined, of which the most important are:\n",
      "     |      \n",
      "     |         - Inheritance: An IS-A relation. The child frame is a subtype\n",
      "     |           of the parent frame, and each FE in the parent is bound to\n",
      "     |           a corresponding FE in the child. An example is the\n",
      "     |           \"Revenge\" frame which inherits from the\n",
      "     |           \"Rewards_and_punishments\" frame.\n",
      "     |      \n",
      "     |         - Using: The child frame presupposes the parent frame as\n",
      "     |           background, e.g the \"Speed\" frame \"uses\" (or presupposes)\n",
      "     |           the \"Motion\" frame; however, not all parent FEs need to be\n",
      "     |           bound to child FEs.\n",
      "     |      \n",
      "     |         - Subframe: The child frame is a subevent of a complex event\n",
      "     |           represented by the parent, e.g. the \"Criminal_process\" frame\n",
      "     |           has subframes of \"Arrest\", \"Arraignment\", \"Trial\", and\n",
      "     |           \"Sentencing\".\n",
      "     |      \n",
      "     |         - Perspective_on: The child frame provides a particular\n",
      "     |           perspective on an un-perspectivized parent frame. A pair of\n",
      "     |           examples consists of the \"Hiring\" and \"Get_a_job\" frames,\n",
      "     |           which perspectivize the \"Employment_start\" frame from the\n",
      "     |           Employer's and the Employee's point of view, respectively.\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to match against\n",
      "     |          Frame names. If 'name' is None, then a list of all\n",
      "     |          Framenet Frames will be returned.\n",
      "     |      :type name: str\n",
      "     |      :return: A list of matching Frames (or all Frames).\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  frames_by_lemma(self, pat)\n",
      "     |      Returns a list of all frames that contain LUs in which the\n",
      "     |      ``name`` attribute of the LU matchs the given regular expression\n",
      "     |      ``pat``. Note that LU names are composed of \"lemma.POS\", where\n",
      "     |      the \"lemma\" part can be made up of either a single lexeme\n",
      "     |      (e.g. 'run') or multiple lexemes (e.g. 'a little').\n",
      "     |      \n",
      "     |      Note: if you are going to be doing a lot of this type of\n",
      "     |      searching, you'd want to build an index that maps from lemmas to\n",
      "     |      frames because each time frames_by_lemma() is called, it has to\n",
      "     |      search through ALL of the frame XML files in the db.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> from nltk.corpus.reader.framenet import PrettyList\n",
      "     |      >>> PrettyList(sorted(fn.frames_by_lemma(r'(?i)a little'), key=itemgetter('ID'))) # doctest: +ELLIPSIS\n",
      "     |      [<frame ID=189 name=Quanti...>, <frame ID=2001 name=Degree>]\n",
      "     |      \n",
      "     |      :return: A list of frame objects.\n",
      "     |      :rtype: list(AttrDict)\n",
      "     |  \n",
      "     |  ft_sents(self, docNamePattern=None)\n",
      "     |      Full-text annotation sentences, optionally filtered by document name.\n",
      "     |  \n",
      "     |  help(self, attrname=None)\n",
      "     |      Display help information summarizing the main methods.\n",
      "     |  \n",
      "     |  lu(self, fn_luid, ignorekeys=[], luName=None, frameID=None, frameName=None)\n",
      "     |      Access a lexical unit by its ID. luName, frameID, and frameName are used\n",
      "     |      only in the event that the LU does not have a file in the database\n",
      "     |      (which is the case for LUs with \"Problem\" status); in this case,\n",
      "     |      a placeholder LU is created which just contains its name, ID, and frame.\n",
      "     |      \n",
      "     |      \n",
      "     |      Usage examples:\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.lu(256).name\n",
      "     |      'foresee.v'\n",
      "     |      >>> fn.lu(256).definition\n",
      "     |      'COD: be aware of beforehand; predict.'\n",
      "     |      >>> fn.lu(256).frame.name\n",
      "     |      'Expectation'\n",
      "     |      >>> pprint(list(map(PrettyDict, fn.lu(256).lexemes)))\n",
      "     |      [{'POS': 'V', 'breakBefore': 'false', 'headword': 'false', 'name': 'foresee', 'order': 1}]\n",
      "     |      \n",
      "     |      >>> fn.lu(227).exemplars[23]\n",
      "     |      exemplar sentence (352962):\n",
      "     |      [sentNo] 0\n",
      "     |      [aPos] 59699508\n",
      "     |      <BLANKLINE>\n",
      "     |      [LU] (227) guess.v in Coming_to_believe\n",
      "     |      <BLANKLINE>\n",
      "     |      [frame] (23) Coming_to_believe\n",
      "     |      <BLANKLINE>\n",
      "     |      [annotationSet] 2 annotation sets\n",
      "     |      <BLANKLINE>\n",
      "     |      [POS] 18 tags\n",
      "     |      <BLANKLINE>\n",
      "     |      [POS_tagset] BNC\n",
      "     |      <BLANKLINE>\n",
      "     |      [GF] 3 relations\n",
      "     |      <BLANKLINE>\n",
      "     |      [PT] 3 phrases\n",
      "     |      <BLANKLINE>\n",
      "     |      [Other] 1 entry\n",
      "     |      <BLANKLINE>\n",
      "     |      [text] + [Target] + [FE]\n",
      "     |      <BLANKLINE>\n",
      "     |      When he was inside the house , Culley noticed the characteristic\n",
      "     |                                                    ------------------\n",
      "     |                                                    Content\n",
      "     |      <BLANKLINE>\n",
      "     |      he would n't have guessed at .\n",
      "     |      --                ******* --\n",
      "     |      Co                        C1 [Evidence:INI]\n",
      "     |       (Co=Cognizer, C1=Content)\n",
      "     |      <BLANKLINE>\n",
      "     |      <BLANKLINE>\n",
      "     |      \n",
      "     |      The dict that is returned from this function will contain most of the\n",
      "     |      following information about the LU. Note that some LUs do not contain\n",
      "     |      all of these pieces of information - particularly 'totalAnnotated' and\n",
      "     |      'incorporatedFE' may be missing in some LUs:\n",
      "     |      \n",
      "     |      - 'name'       : the name of the LU (e.g. 'merger.n')\n",
      "     |      - 'definition' : textual definition of the LU\n",
      "     |      - 'ID'         : the internal ID number of the LU\n",
      "     |      - '_type'      : 'lu'\n",
      "     |      - 'status'     : e.g. 'Created'\n",
      "     |      - 'frame'      : Frame that this LU belongs to\n",
      "     |      - 'POS'        : the part of speech of this LU (e.g. 'N')\n",
      "     |      - 'totalAnnotated' : total number of examples annotated with this LU\n",
      "     |      - 'incorporatedFE' : FE that incorporates this LU (e.g. 'Ailment')\n",
      "     |      - 'sentenceCount'  : a dict with the following two keys:\n",
      "     |               - 'annotated': number of sentences annotated with this LU\n",
      "     |               - 'total'    : total number of sentences with this LU\n",
      "     |      \n",
      "     |      - 'lexemes'  : a list of dicts describing the lemma of this LU.\n",
      "     |         Each dict in the list contains these keys:\n",
      "     |         - 'POS'     : part of speech e.g. 'N'\n",
      "     |         - 'name'    : either single-lexeme e.g. 'merger' or\n",
      "     |                       multi-lexeme e.g. 'a little'\n",
      "     |         - 'order': the order of the lexeme in the lemma (starting from 1)\n",
      "     |         - 'headword': a boolean ('true' or 'false')\n",
      "     |         - 'breakBefore': Can this lexeme be separated from the previous lexeme?\n",
      "     |              Consider: \"take over.v\" as in:\n",
      "     |                       Germany took over the Netherlands in 2 days.\n",
      "     |                       Germany took the Netherlands over in 2 days.\n",
      "     |              In this case, 'breakBefore' would be \"true\" for the lexeme\n",
      "     |              \"over\". Contrast this with \"take after.v\" as in:\n",
      "     |                       Mary takes after her grandmother.\n",
      "     |                      *Mary takes her grandmother after.\n",
      "     |              In this case, 'breakBefore' would be \"false\" for the lexeme \"after\"\n",
      "     |      \n",
      "     |      - 'lemmaID'    : Can be used to connect lemmas in different LUs\n",
      "     |      - 'semTypes'   : a list of semantic type objects for this LU\n",
      "     |      - 'subCorpus'  : a list of subcorpora\n",
      "     |         - Each item in the list is a dict containing the following keys:\n",
      "     |            - 'name' :\n",
      "     |            - 'sentence' : a list of sentences in the subcorpus\n",
      "     |               - each item in the list is a dict with the following keys:\n",
      "     |                  - 'ID':\n",
      "     |                  - 'sentNo':\n",
      "     |                  - 'text': the text of the sentence\n",
      "     |                  - 'aPos':\n",
      "     |                  - 'annotationSet': a list of annotation sets\n",
      "     |                     - each item in the list is a dict with the following keys:\n",
      "     |                        - 'ID':\n",
      "     |                        - 'status':\n",
      "     |                        - 'layer': a list of layers\n",
      "     |                           - each layer is a dict containing the following keys:\n",
      "     |                              - 'name': layer name (e.g. 'BNC')\n",
      "     |                              - 'rank':\n",
      "     |                              - 'label': a list of labels for the layer\n",
      "     |                                 - each label is a dict containing the following keys:\n",
      "     |                                    - 'start': start pos of label in sentence 'text' (0-based)\n",
      "     |                                    - 'end': end pos of label in sentence 'text' (0-based)\n",
      "     |                                    - 'name': name of label (e.g. 'NN1')\n",
      "     |      \n",
      "     |      Under the hood, this implementation looks up the lexical unit information\n",
      "     |      in the *frame* definition file. That file does not contain\n",
      "     |      corpus annotations, so the LU files will be accessed on demand if those are\n",
      "     |      needed. In principle, valence patterns could be loaded here too,\n",
      "     |      though these are not currently supported.\n",
      "     |      \n",
      "     |      :param fn_luid: The id number of the lexical unit\n",
      "     |      :type fn_luid: int\n",
      "     |      :param ignorekeys: The keys to ignore. These keys will not be\n",
      "     |          included in the output. (optional)\n",
      "     |      :type ignorekeys: list(str)\n",
      "     |      :return: All information about the lexical unit\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  lu_basic(self, fn_luid)\n",
      "     |      Returns basic information about the LU whose id is\n",
      "     |      ``fn_luid``. This is basically just a wrapper around the\n",
      "     |      ``lu()`` function with \"subCorpus\" info excluded.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> lu = PrettyDict(fn.lu_basic(256), breakLines=True)\n",
      "     |      >>> # ellipses account for differences between FN 1.5 and 1.7\n",
      "     |      >>> lu # doctest: +ELLIPSIS\n",
      "     |      {'ID': 256,\n",
      "     |       'POS': 'V',\n",
      "     |       'URL': u'https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu256.xml',\n",
      "     |       '_type': 'lu',\n",
      "     |       'cBy': ...,\n",
      "     |       'cDate': '02/08/2001 01:27:50 PST Thu',\n",
      "     |       'definition': 'COD: be aware of beforehand; predict.',\n",
      "     |       'definitionMarkup': 'COD: be aware of beforehand; predict.',\n",
      "     |       'frame': <frame ID=26 name=Expectation>,\n",
      "     |       'lemmaID': 15082,\n",
      "     |       'lexemes': [{'POS': 'V', 'breakBefore': 'false', 'headword': 'false', 'name': 'foresee', 'order': 1}],\n",
      "     |       'name': 'foresee.v',\n",
      "     |       'semTypes': [],\n",
      "     |       'sentenceCount': {'annotated': ..., 'total': ...},\n",
      "     |       'status': 'FN1_Sent'}\n",
      "     |      \n",
      "     |      :param fn_luid: The id number of the desired LU\n",
      "     |      :type fn_luid: int\n",
      "     |      :return: Basic information about the lexical unit\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  lu_ids_and_names(self, name=None)\n",
      "     |      Uses the LU index, which is much faster than looking up each LU definition\n",
      "     |      if only the names and IDs are needed.\n",
      "     |  \n",
      "     |  lus(self, name=None, frame=None)\n",
      "     |      Obtain details for lexical units.\n",
      "     |      Optionally restrict by lexical unit name pattern, and/or to a certain frame\n",
      "     |      or frames whose name matches a pattern.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> len(fn.lus()) in (11829, 13572) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> PrettyList(sorted(fn.lus(r'(?i)a little'), key=itemgetter('ID')), maxReprSize=0, breakLines=True)\n",
      "     |      [<lu ID=14733 name=a little.n>,\n",
      "     |       <lu ID=14743 name=a little.adv>,\n",
      "     |       <lu ID=14744 name=a little bit.adv>]\n",
      "     |      >>> PrettyList(sorted(fn.lus(r'interest', r'(?i)stimulus'), key=itemgetter('ID')))\n",
      "     |      [<lu ID=14894 name=interested.a>, <lu ID=14920 name=interesting.a>]\n",
      "     |      \n",
      "     |      A brief intro to Lexical Units (excerpted from \"FrameNet II:\n",
      "     |      Extended Theory and Practice\" by Ruppenhofer et. al., 2010):\n",
      "     |      \n",
      "     |      A lexical unit (LU) is a pairing of a word with a meaning. For\n",
      "     |      example, the \"Apply_heat\" Frame describes a common situation\n",
      "     |      involving a Cook, some Food, and a Heating Instrument, and is\n",
      "     |      _evoked_ by words such as bake, blanch, boil, broil, brown,\n",
      "     |      simmer, steam, etc. These frame-evoking words are the LUs in the\n",
      "     |      Apply_heat frame. Each sense of a polysemous word is a different\n",
      "     |      LU.\n",
      "     |      \n",
      "     |      We have used the word \"word\" in talking about LUs. The reality\n",
      "     |      is actually rather complex. When we say that the word \"bake\" is\n",
      "     |      polysemous, we mean that the lemma \"bake.v\" (which has the\n",
      "     |      word-forms \"bake\", \"bakes\", \"baked\", and \"baking\") is linked to\n",
      "     |      three different frames:\n",
      "     |      \n",
      "     |         - Apply_heat: \"Michelle baked the potatoes for 45 minutes.\"\n",
      "     |      \n",
      "     |         - Cooking_creation: \"Michelle baked her mother a cake for her birthday.\"\n",
      "     |      \n",
      "     |         - Absorb_heat: \"The potatoes have to bake for more than 30 minutes.\"\n",
      "     |      \n",
      "     |      These constitute three different LUs, with different\n",
      "     |      definitions.\n",
      "     |      \n",
      "     |      Multiword expressions such as \"given name\" and hyphenated words\n",
      "     |      like \"shut-eye\" can also be LUs. Idiomatic phrases such as\n",
      "     |      \"middle of nowhere\" and \"give the slip (to)\" are also defined as\n",
      "     |      LUs in the appropriate frames (\"Isolated_places\" and \"Evading\",\n",
      "     |      respectively), and their internal structure is not analyzed.\n",
      "     |      \n",
      "     |      Framenet provides multiple annotated examples of each sense of a\n",
      "     |      word (i.e. each LU).  Moreover, the set of examples\n",
      "     |      (approximately 20 per LU) illustrates all of the combinatorial\n",
      "     |      possibilities of the lexical unit.\n",
      "     |      \n",
      "     |      Each LU is linked to a Frame, and hence to the other words which\n",
      "     |      evoke that Frame. This makes the FrameNet database similar to a\n",
      "     |      thesaurus, grouping together semantically similar words.\n",
      "     |      \n",
      "     |      In the simplest case, frame-evoking words are verbs such as\n",
      "     |      \"fried\" in:\n",
      "     |      \n",
      "     |         \"Matilde fried the catfish in a heavy iron skillet.\"\n",
      "     |      \n",
      "     |      Sometimes event nouns may evoke a Frame. For example,\n",
      "     |      \"reduction\" evokes \"Cause_change_of_scalar_position\" in:\n",
      "     |      \n",
      "     |         \"...the reduction of debt levels to $665 million from $2.6 billion.\"\n",
      "     |      \n",
      "     |      Adjectives may also evoke a Frame. For example, \"asleep\" may\n",
      "     |      evoke the \"Sleep\" frame as in:\n",
      "     |      \n",
      "     |         \"They were asleep for hours.\"\n",
      "     |      \n",
      "     |      Many common nouns, such as artifacts like \"hat\" or \"tower\",\n",
      "     |      typically serve as dependents rather than clearly evoking their\n",
      "     |      own frames.\n",
      "     |      \n",
      "     |      :param name: A regular expression pattern used to search the LU\n",
      "     |          names. Note that LU names take the form of a dotted\n",
      "     |          string (e.g. \"run.v\" or \"a little.adv\") in which a\n",
      "     |          lemma preceeds the \".\" and a POS follows the\n",
      "     |          dot. The lemma may be composed of a single lexeme\n",
      "     |          (e.g. \"run\") or of multiple lexemes (e.g. \"a\n",
      "     |          little\"). If 'name' is not given, then all LUs will\n",
      "     |          be returned.\n",
      "     |      \n",
      "     |          The valid POSes are:\n",
      "     |      \n",
      "     |                 v    - verb\n",
      "     |                 n    - noun\n",
      "     |                 a    - adjective\n",
      "     |                 adv  - adverb\n",
      "     |                 prep - preposition\n",
      "     |                 num  - numbers\n",
      "     |                 intj - interjection\n",
      "     |                 art  - article\n",
      "     |                 c    - conjunction\n",
      "     |                 scon - subordinating conjunction\n",
      "     |      \n",
      "     |      :type name: str\n",
      "     |      :type frame: str or int or frame\n",
      "     |      :return: A list of selected (or all) lexical units\n",
      "     |      :rtype: list of LU objects (dicts). See the lu() function for info\n",
      "     |        about the specifics of LU objects.\n",
      "     |  \n",
      "     |  propagate_semtypes(self)\n",
      "     |      Apply inference rules to distribute semtypes over relations between FEs.\n",
      "     |      For FrameNet 1.5, this results in 1011 semtypes being propagated.\n",
      "     |      (Not done by default because it requires loading all frame files,\n",
      "     |      which takes several seconds. If this needed to be fast, it could be rewritten\n",
      "     |      to traverse the neighboring relations on demand for each FE semtype.)\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> x = sum(1 for f in fn.frames() for fe in f.FE.values() if fe.semType)\n",
      "     |      >>> fn.propagate_semtypes()\n",
      "     |      >>> y = sum(1 for f in fn.frames() for fe in f.FE.values() if fe.semType)\n",
      "     |      >>> y-x > 1000\n",
      "     |      True\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README.txt (or README) file.\n",
      "     |  \n",
      "     |  semtype(self, key)\n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> fn.semtype(233).name\n",
      "     |      'Temperature'\n",
      "     |      >>> fn.semtype(233).abbrev\n",
      "     |      'Temp'\n",
      "     |      >>> fn.semtype('Temperature').ID\n",
      "     |      233\n",
      "     |      \n",
      "     |      :param key: The name, abbreviation, or id number of the semantic type\n",
      "     |      :type key: string or int\n",
      "     |      :return: Information about a semantic type\n",
      "     |      :rtype: dict\n",
      "     |  \n",
      "     |  semtype_inherits(self, st, superST)\n",
      "     |  \n",
      "     |  semtypes(self)\n",
      "     |      Obtain a list of semantic types.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import framenet as fn\n",
      "     |      >>> stypes = fn.semtypes()\n",
      "     |      >>> len(stypes) in (73, 109) # FN 1.5 and 1.7, resp.\n",
      "     |      True\n",
      "     |      >>> sorted(stypes[0].keys())\n",
      "     |      ['ID', '_type', 'abbrev', 'definition', 'definitionMarkup', 'name', 'rootType', 'subTypes', 'superType']\n",
      "     |      \n",
      "     |      :return: A list of all of the semantic types in framenet\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  sents(self, exemplars=True, full_text=True)\n",
      "     |      Annotated sentences matching the specified criteria.\n",
      "     |  \n",
      "     |  warnings(self, v)\n",
      "     |      Enable or disable warnings of data integrity issues as they are encountered.\n",
      "     |      If v is truthy, warnings will be enabled.\n",
      "     |      \n",
      "     |      (This is a function rather than just an attribute/property to ensure that if\n",
      "     |      enabling warnings is the first action taken, the corpus reader is instantiated first.)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IEERCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  IEERCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IEERCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  docs(self, fileids=None)\n",
      "     |  \n",
      "     |  parsed_docs(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IPIPANCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  IPIPANCorpusReader(root, fileids)\n",
      "     |  \n",
      "     |  Corpus reader designed to work with corpus created by IPI PAN.\n",
      "     |  See http://korpus.pl/en/ for more details about IPI PAN corpus.\n",
      "     |  \n",
      "     |  The corpus includes information about text domain, channel and categories.\n",
      "     |  You can access possible values using ``domains()``, ``channels()`` and\n",
      "     |  ``categories()``. You can use also this metadata to filter files, e.g.:\n",
      "     |  ``fileids(channel='prasa')``, ``fileids(categories='publicystyczny')``.\n",
      "     |  \n",
      "     |  The reader supports methods: words, sents, paras and their tagged versions.\n",
      "     |  You can get part of speech instead of full tag by giving \"simplify_tags=True\"\n",
      "     |  parameter, e.g.: ``tagged_sents(simplify_tags=True)``.\n",
      "     |  \n",
      "     |  Also you can get all tags disambiguated tags specifying parameter\n",
      "     |  \"one_tag=False\", e.g.: ``tagged_paras(one_tag=False)``.\n",
      "     |  \n",
      "     |  You can get all tags that were assigned by a morphological analyzer specifying\n",
      "     |  parameter \"disamb_only=False\", e.g. ``tagged_words(disamb_only=False)``.\n",
      "     |  \n",
      "     |  The IPIPAN Corpus contains tags indicating if there is a space between two\n",
      "     |  tokens. To add special \"no space\" markers, you should specify parameter\n",
      "     |  \"append_no_space=True\", e.g. ``tagged_words(append_no_space=True)``.\n",
      "     |  As a result in place where there should be no space between two tokens new\n",
      "     |  pair ('', 'no-space') will be inserted (for tagged data) and just '' for\n",
      "     |  methods without tags.\n",
      "     |  \n",
      "     |  The corpus reader can also try to append spaces between words. To enable this\n",
      "     |  option, specify parameter \"append_space=True\", e.g. ``words(append_space=True)``.\n",
      "     |  As a result either ' ' or (' ', 'space') will be inserted between tokens.\n",
      "     |  \n",
      "     |  By default, xml entities like &quot; and &amp; are replaced by corresponding\n",
      "     |  characters. You can turn off this feature, specifying parameter\n",
      "     |  \"replace_xmlentities=False\", e.g. ``words(replace_xmlentities=False)``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IPIPANCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |  \n",
      "     |  channels(self, fileids=None)\n",
      "     |  \n",
      "     |  domains(self, fileids=None)\n",
      "     |  \n",
      "     |  fileids(self, channels=None, domains=None, categories=None)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  paras(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  words(self, fileids=None, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class IndianCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  IndianCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndianCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class KNBCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  KNBCorpusReader(root, fileids, encoding='utf8', morphs2str=<function <lambda> at 0x00000207D8C495E8>)\n",
      "     |  \n",
      "     |  This class implements:\n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  The structure of tagged words:\n",
      "     |    tagged_word = (word(str), tags(tuple))\n",
      "     |    tags = (surface, reading, lemma, pos1, posid1, pos2, posid2, pos3, posid3, others ...)\n",
      "     |  \n",
      "     |  Usage example\n",
      "     |  -------------\n",
      "     |  \n",
      "     |  >>> from nltk.corpus.util import LazyCorpusLoader\n",
      "     |  >>> knbc = LazyCorpusLoader(\n",
      "     |  ...     'knbc/corpus1',\n",
      "     |  ...     KNBCorpusReader,\n",
      "     |  ...     r'.*/KN.*',\n",
      "     |  ...     encoding='euc-jp',\n",
      "     |  ... )\n",
      "     |  \n",
      "     |  >>> len(knbc.sents()[0])\n",
      "     |  9\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KNBCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', morphs2str=<function <lambda> at 0x00000207D8C495E8>)\n",
      "     |      Initialize KNBCorpusReader\n",
      "     |      morphs2str is a function to convert morphlist to str for tree representation\n",
      "     |      for _parse()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class LinThesaurusCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  LinThesaurusCorpusReader(root, badscore=0.0)\n",
      "     |  \n",
      "     |  Wrapper for the LISP-formatted thesauruses distributed by Dekang Lin.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LinThesaurusCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, ngram)\n",
      "     |      Determines whether or not the given ngram is in the thesaurus.\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :return: whether the given ngram is in the thesaurus.\n",
      "     |  \n",
      "     |  __init__(self, root, badscore=0.0)\n",
      "     |      Initialize the thesaurus.\n",
      "     |      \n",
      "     |      :param root: root directory containing thesaurus LISP files\n",
      "     |      :type root: C{string}\n",
      "     |      :param badscore: the score to give to words which do not appear in each other's sets of synonyms\n",
      "     |      :type badscore: C{float}\n",
      "     |  \n",
      "     |  scored_synonyms(self, ngram, fileid=None)\n",
      "     |      Returns a list of scored synonyms (tuples of synonyms and scores) for the current ngram\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, list of tuples of scores and synonyms; otherwise,\n",
      "     |               list of tuples of fileids and lists, where inner lists consist of tuples of\n",
      "     |               scores and synonyms.\n",
      "     |  \n",
      "     |  similarity(self, ngram1, ngram2, fileid=None)\n",
      "     |      Returns the similarity score for two ngrams.\n",
      "     |      \n",
      "     |      :param ngram1: first ngram to compare\n",
      "     |      :type ngram1: C{string}\n",
      "     |      :param ngram2: second ngram to compare\n",
      "     |      :type ngram2: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, just the score for the two ngrams; otherwise,\n",
      "     |               list of tuples of fileids and scores.\n",
      "     |  \n",
      "     |  synonyms(self, ngram, fileid=None)\n",
      "     |      Returns a list of synonyms for the current ngram.\n",
      "     |      \n",
      "     |      :param ngram: ngram to lookup\n",
      "     |      :type ngram: C{string}\n",
      "     |      :param fileid: thesaurus fileid to search in. If None, search all fileids.\n",
      "     |      :type fileid: C{string}\n",
      "     |      :return: If fileid is specified, list of synonyms; otherwise, list of tuples of fileids and\n",
      "     |               lists, where inner lists contain synonyms.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MTECorpusReader(nltk.corpus.reader.tagged.TaggedCorpusReader)\n",
      "     |  MTECorpusReader(root=None, fileids=None, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for corpora following the TEI-p5 xml scheme, such as MULTEXT-East.\n",
      "     |  MULTEXT-East contains part-of-speech-tagged words with a quite precise tagging\n",
      "     |  scheme. These tags can be converted to the Universal tagset\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MTECorpusReader\n",
      "     |      nltk.corpus.reader.tagged.TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root=None, fileids=None, encoding='utf8')\n",
      "     |      Construct a new MTECorpusreader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = MTECorpusReader(root, 'oana-*.xml', 'utf8') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus. (default points to location in multext config file)\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus. (default is oana-en.xml)\n",
      "     |      :param enconding: The encoding of the given files (default is utf8)\n",
      "     |  \n",
      "     |  lemma_paras(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a\n",
      "     |               list of sentences, which are in turn encoded as a list of\n",
      "     |               tuples of the word and the corresponding lemma (word, lemma)\n",
      "     |      :rtype: list(List(List(tuple(str, str))))\n",
      "     |  \n",
      "     |  lemma_sents(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |               encoded as a list of tuples of the word and the corresponding\n",
      "     |               lemma (word, lemma)\n",
      "     |      :rtype: list(list(tuple(str, str)))\n",
      "     |  \n",
      "     |  lemma_words(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of words, the corresponding lemmas\n",
      "     |               and punctuation symbols, encoded as tuples (word, lemma)\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a list\n",
      "     |               of sentences, which are in turn encoded as lists of word string\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Prints some information about this corpus.\n",
      "     |      :return: the content of the attached README file\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of sentences or utterances,\n",
      "     |               each encoded as a list of word strings\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of paragraphs, each encoded as a\n",
      "     |               list of sentences, which are in turn encoded as a list\n",
      "     |               of (word,tag) tuples\n",
      "     |      :rtype: list(list(list(tuple(str, str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of sentences or utterances, each\n",
      "     |               each encoded as a list of (word,tag) tuples\n",
      "     |      :rtype: list(list(tuple(str, str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset='msd', tags='')\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :param tagset: The tagset that should be used in the returned object,\n",
      "     |                     either \"universal\" or \"msd\", \"msd\" is the default\n",
      "     |      :param tags: An MSD Tag that is used to filter all parts of the used corpus\n",
      "     |                   that are not more precise or at least equal to the given tag\n",
      "     |      :return: the given file(s) as a list of tagged words and punctuation symbols\n",
      "     |               encoded as tuples (word, tag)\n",
      "     |      :rtype: list(tuple(str, str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |          :param fileids: A list specifying the fileids that should be used.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MWAPPDBCorpusReader(WordListCorpusReader)\n",
      "     |  MWAPPDBCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  This class is used to read the list of word pairs from the subset of lexical\n",
      "     |  pairs of The Paraphrase Database (PPDB) XXXL used in the Monolingual Word\n",
      "     |  Alignment (MWA) algorithm described in Sultan et al. (2014a, 2014b, 2015):\n",
      "     |   - http://acl2014.org/acl2014/Q14/pdf/Q14-1017\n",
      "     |   - http://www.aclweb.org/anthology/S14-2039\n",
      "     |   - http://www.aclweb.org/anthology/S15-2027\n",
      "     |  \n",
      "     |  The original source of the full PPDB corpus can be found on\n",
      "     |  http://www.cis.upenn.edu/~ccb/ppdb/\n",
      "     |  \n",
      "     |  :return: a list of tuples of similar lexical terms.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MWAPPDBCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids='ppdb-1.0-xxxl-lexical.extended.synonyms.uniquepairs')\n",
      "     |      :return: a tuple of synonym word pairs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  mwa_ppdb_xxxl_file = 'ppdb-1.0-xxxl-lexical.extended.synonyms.uniquepa...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class MacMorphoCorpusReader(TaggedCorpusReader)\n",
      "     |  MacMorphoCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A corpus reader for the MAC_MORPHO corpus.  Each line contains a\n",
      "     |  single tagged word, using '_' as a separator.  Sentence boundaries\n",
      "     |  are based on the end-sentence tag ('_.').  Paragraph information\n",
      "     |  is not included in the corpus, so each paragraph returned by\n",
      "     |  ``self.paras()`` and ``self.tagged_paras()`` contains a single\n",
      "     |  sentence.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MacMorphoCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from TaggedCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NKJPCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  NKJPCorpusReader(root, fileids='.*')\n",
      "     |  \n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NKJPCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids='.*')\n",
      "     |      Corpus reader designed to work with National Corpus of Polish.\n",
      "     |      See http://nkjp.pl/ for more details about NKJP.\n",
      "     |      use example:\n",
      "     |      import nltk\n",
      "     |      import nkjp\n",
      "     |      from nkjp import NKJPCorpusReader\n",
      "     |      x = NKJPCorpusReader(root='/home/USER/nltk_data/corpora/nkjp/', fileids='') # obtain the whole corpus\n",
      "     |      x.header()\n",
      "     |      x.raw()\n",
      "     |      x.words()\n",
      "     |      x.tagged_words(tags=['subst', 'comp'])  #Link to find more tags: nkjp.pl/poliqarp/help/ense2.html\n",
      "     |      x.sents()\n",
      "     |      x = NKJPCorpusReader(root='/home/USER/nltk_data/corpora/nkjp/', fileids='Wilk*') # obtain particular file(s)\n",
      "     |      x.header(fileids=['WilkDom', '/home/USER/nltk_data/corpora/nkjp/WilkWilczy'])\n",
      "     |      x.tagged_words(fileids=['WilkDom', '/home/USER/nltk_data/corpora/nkjp/WilkWilczy'], tags=['subst', 'comp'])\n",
      "     |  \n",
      "     |  add_root(self, fileid)\n",
      "     |      Add root if necessary to specified fileid.\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Returns a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  get_paths(self)\n",
      "     |  \n",
      "     |  header(self, fileids=None, **kwargs)\n",
      "     |      Returns header(s) of specified fileids.\n",
      "     |  \n",
      "     |  raw(self, fileids=None, **kwargs)\n",
      "     |      Returns words in specified fileids.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, **kwargs)\n",
      "     |      Returns sentences in specified fileids.\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, **kwargs)\n",
      "     |      Call with specified tags as a list, e.g. tags=['subst', 'comp'].\n",
      "     |      Returns tagged words in specified fileids.\n",
      "     |  \n",
      "     |  words(self, fileids=None, **kwargs)\n",
      "     |      Returns words in specified fileids.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  HEADER_MODE = 2\n",
      "     |  \n",
      "     |  RAW_MODE = 3\n",
      "     |  \n",
      "     |  SENTS_MODE = 1\n",
      "     |  \n",
      "     |  WORDS_MODE = 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NPSChatCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  NPSChatCorpusReader(root, fileids, wrap_etree=False, tagset=None)\n",
      "     |  \n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NPSChatCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False, tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  posts(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_posts(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml_posts(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NombankCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  NombankCorpusReader(root, nomfile, framefiles='', nounsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |  \n",
      "     |  Corpus reader for the nombank corpus, which augments the Penn\n",
      "     |  Treebank with information about the predicate argument structure\n",
      "     |  of every noun instance.  The corpus consists of two parts: the\n",
      "     |  predicate-argument annotations themselves, and a set of \"frameset\n",
      "     |  files\" which define the argument labels used by the annotations,\n",
      "     |  on a per-noun basis.  Each \"frameset file\" contains one or more\n",
      "     |  predicates, such as ``'turn'`` or ``'turn_on'``, each of which is\n",
      "     |  divided into coarse-grained word senses called \"rolesets\".  For\n",
      "     |  each \"roleset\", the frameset file provides descriptions of the\n",
      "     |  argument roles, along with examples.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NombankCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, nomfile, framefiles='', nounsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param nomfile: The name of the file containing the predicate-\n",
      "     |          argument annotations (relative to ``root``).\n",
      "     |      :param framefiles: A list or regexp specifying the frameset\n",
      "     |          fileids for this corpus.\n",
      "     |      :param parse_fileid_xform: A transform that should be applied\n",
      "     |          to the fileids in this corpus.  This should be a function\n",
      "     |          of one argument (a fileid) that returns a string (the new\n",
      "     |          fileid).\n",
      "     |      :param parse_corpus: The corpus containing the parse trees\n",
      "     |          corresponding to this corpus.  These parse trees are\n",
      "     |          necessary to resolve the tree pointers used by nombank.\n",
      "     |  \n",
      "     |  instances(self, baseform=None)\n",
      "     |      :return: a corpus view that acts as a list of\n",
      "     |      ``NombankInstance`` objects, one for each noun in the corpus.\n",
      "     |  \n",
      "     |  lines(self)\n",
      "     |      :return: a corpus view that acts as a list of strings, one for\n",
      "     |      each line in the predicate-argument annotation file.\n",
      "     |  \n",
      "     |  nouns(self)\n",
      "     |      :return: a corpus view that acts as a list of all noun lemmas\n",
      "     |      in this corpus (from the nombank.1.0.words file).\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  roleset(self, roleset_id)\n",
      "     |      :return: the xml description for the given roleset.\n",
      "     |  \n",
      "     |  rolesets(self, baseform=None)\n",
      "     |      :return: list of xml descriptions for rolesets.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class NonbreakingPrefixesCorpusReader(WordListCorpusReader)\n",
      "     |  NonbreakingPrefixesCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  This is a class to read the nonbreaking prefixes textfiles from the\n",
      "     |  Moses Machine Translation toolkit. These lists are used in the Python port\n",
      "     |  of the Moses' word tokenizer.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NonbreakingPrefixesCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  words(self, lang=None, fileids=None, ignore_lines_startswith='#')\n",
      "     |      This module returns a list of nonbreaking prefixes for the specified\n",
      "     |      language(s).\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import nonbreaking_prefixes as nbp\n",
      "     |      >>> nbp.words('en')[:10] == [u'A', u'B', u'C', u'D', u'E', u'F', u'G', u'H', u'I', u'J']\n",
      "     |      True\n",
      "     |      >>> nbp.words('ta')[:5] == [u'', u'', u'', u'', u'']\n",
      "     |      True\n",
      "     |      \n",
      "     |      :return: a list words for the specified language(s).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  available_langs = {'ca': 'ca', 'catalan': 'ca', 'cs': 'cs', 'czech': '...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class OpinionLexiconCorpusReader(nltk.corpus.reader.wordlist.WordListCorpusReader)\n",
      "     |  OpinionLexiconCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for Liu and Hu opinion lexicon.  Blank lines and readme are ignored.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import opinion_lexicon\n",
      "     |      >>> opinion_lexicon.words()\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', ...]\n",
      "     |  \n",
      "     |  The OpinionLexiconCorpusReader provides shortcuts to retrieve positive/negative\n",
      "     |  words:\n",
      "     |  \n",
      "     |      >>> opinion_lexicon.negative()\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', ...]\n",
      "     |  \n",
      "     |  Note that words from `words()` method are sorted by file id, not alphabetically:\n",
      "     |  \n",
      "     |      >>> opinion_lexicon.words()[0:10]\n",
      "     |      ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably',\n",
      "     |      'abominate', 'abomination', 'abort', 'aborted']\n",
      "     |      >>> sorted(opinion_lexicon.words())[0:10]\n",
      "     |      ['2-faced', '2-faces', 'a+', 'abnormal', 'abolish', 'abominable', 'abominably',\n",
      "     |      'abominate', 'abomination', 'abort']\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpinionLexiconCorpusReader\n",
      "     |      nltk.corpus.reader.wordlist.WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  negative(self)\n",
      "     |      Return all negative words in alphabetical order.\n",
      "     |      \n",
      "     |      :return: a list of negative words.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  positive(self)\n",
      "     |      Return all positive words in alphabetical order.\n",
      "     |      \n",
      "     |      :return: a list of positive words.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words in the opinion lexicon. Note that these words are not\n",
      "     |      sorted in alphabetical order.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.opinion_lexicon.IgnoreReadmeCo...\n",
      "     |      This CorpusView is used to skip the initial readme block of the corpus.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.wordlist.WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PPAttachmentCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  PPAttachmentCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  sentence_id verb noun1 preposition noun2 attachment\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PPAttachmentCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  attachments(self, fileids)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  tuples(self, fileids)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PanLexLiteCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  PanLexLiteCorpusReader(root)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PanLexLiteCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  language_varieties(self, lc=None)\n",
      "     |      Return a list of PanLex language varieties.\n",
      "     |      \n",
      "     |      :param lc: ISO 639 alpha-3 code. If specified, filters returned varieties\n",
      "     |          by this code. If unspecified, all varieties are returned.\n",
      "     |      :return: the specified language varieties as a list of tuples. The first\n",
      "     |          element is the language variety's seven-character uniform identifier,\n",
      "     |          and the second element is its default name.\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  meanings(self, expr_uid, expr_tt)\n",
      "     |      Return a list of meanings for an expression.\n",
      "     |      \n",
      "     |      :param expr_uid: the expression's language variety, as a seven-character\n",
      "     |          uniform identifier.\n",
      "     |      :param expr_tt: the expression's text.\n",
      "     |      :return: a list of Meaning objects.\n",
      "     |      :rtype: list(Meaning)\n",
      "     |  \n",
      "     |  translations(self, from_uid, from_tt, to_uid)\n",
      "     |      Return a list of translations for an expression into a single language\n",
      "     |          variety.\n",
      "     |      \n",
      "     |      :param from_uid: the source expression's language variety, as a\n",
      "     |          seven-character uniform identifier.\n",
      "     |      :param from_tt: the source expression's text.\n",
      "     |      :param to_uid: the target language variety, as a seven-character\n",
      "     |          uniform identifier.\n",
      "     |      :return a list of translation tuples. The first element is the expression\n",
      "     |          text and the second element is the translation quality.\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MEANING_Q = '\\n        SELECT dnx2.mn, dnx2.uq, dnx2.ap, dnx2.... AND ...\n",
      "     |  \n",
      "     |  TRANSLATION_Q = '\\n        SELECT s.tt, sum(s.uq) AS trq FROM (\\n  ......\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PanlexSwadeshCorpusReader(nltk.corpus.reader.wordlist.WordListCorpusReader)\n",
      "     |  PanlexSwadeshCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  This is a class to read the PanLex Swadesh list from\n",
      "     |  \n",
      "     |  David Kamholz, Jonathan Pool, and Susan M. Colowick (2014).\n",
      "     |  PanLex: Building a Resource for Panlingual Lexical Translation.\n",
      "     |  In LREC. http://www.lrec-conf.org/proceedings/lrec2014/pdf/1029_Paper.pdf\n",
      "     |  \n",
      "     |  License: CC0 1.0 Universal\n",
      "     |  https://creativecommons.org/publicdomain/zero/1.0/legalcode\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PanlexSwadeshCorpusReader\n",
      "     |      nltk.corpus.reader.wordlist.WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  entries(self, fileids=None)\n",
      "     |      :return: a tuple of words for the specified fileids.\n",
      "     |  \n",
      "     |  get_languages(self)\n",
      "     |  \n",
      "     |  get_macrolanguages(self)\n",
      "     |  \n",
      "     |  language_codes(self)\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  words_by_iso639(self, iso63_code)\n",
      "     |      :return: a list of list(str)\n",
      "     |  \n",
      "     |  words_by_lang(self, lang_code)\n",
      "     |      :return: a list of list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.wordlist.WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class Pl196xCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  Pl196xCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A mixin class used to aid in the implementation of corpus readers\n",
      "     |  for categorized corpora.  This class defines the method\n",
      "     |  ``categories()``, which returns a list of the categories for the\n",
      "     |  corpus or for a specified set of fileids; and overrides ``fileids()``\n",
      "     |  to take a ``categories`` argument, restricting the set of fileids to\n",
      "     |  be returned.\n",
      "     |  \n",
      "     |  Subclasses are expected to:\n",
      "     |  \n",
      "     |    - Call ``__init__()`` to set up the mapping.\n",
      "     |  \n",
      "     |    - Override all view methods to accept a ``categories`` parameter,\n",
      "     |      which can be used *instead* of the ``fileids`` parameter, to\n",
      "     |      select which fileids should be included in the returned view.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Pl196xCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize this mapping based on keyword arguments, as\n",
      "     |      follows:\n",
      "     |      \n",
      "     |        - cat_pattern: A regular expression pattern used to find the\n",
      "     |          category for each file identifier.  The pattern will be\n",
      "     |          applied to each file identifier, and the first matching\n",
      "     |          group will be used as the category label for that file.\n",
      "     |      \n",
      "     |        - cat_map: A dictionary, mapping from file identifiers to\n",
      "     |          category labels.\n",
      "     |      \n",
      "     |        - cat_file: The name of a file that contains the mapping\n",
      "     |          from file identifiers to categories.  The argument\n",
      "     |          ``cat_delimiter`` can be used to specify a delimiter.\n",
      "     |      \n",
      "     |      The corresponding argument will be deleted from ``kwargs``.  If\n",
      "     |      more than one argument is specified, an exception will be\n",
      "     |      raised.\n",
      "     |  \n",
      "     |  decode_tag(self, tag)\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, categories=None, textids=None)\n",
      "     |  \n",
      "     |  textids(self, fileids=None, categories=None)\n",
      "     |      In the pl196x corpus each category is stored in single\n",
      "     |      file and thus both methods provide identical functionality. In order\n",
      "     |      to accommodate finer granularity, a non-standard textids() method was\n",
      "     |      implemented. All the main functions can be supplied with a list\n",
      "     |      of required chunks---giving much more control to the user.\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None, textids=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileids=None, categories=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  head_len = 2770\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PlaintextCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  PlaintextCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x00000207D8B75108>, para_block_reader=<function read_blankline_block at 0x00000207D8B81558>, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for corpora that consist of plaintext documents.  Paragraphs\n",
      "     |  are assumed to be split using blank lines.  Sentences and words can\n",
      "     |  be tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specificed as parameters to the constructor.\n",
      "     |  \n",
      "     |  This corpus reader can be customized (e.g., to skip preface\n",
      "     |  sections of specific document formats) by creating a subclass and\n",
      "     |  overriding the ``CorpusView`` class variable.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x00000207D8B75108>, para_block_reader=<function read_blankline_block at 0x00000207D8B81558>, encoding='utf8')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PortugueseCategorizedPlaintextCorpusReader(CategorizedPlaintextCorpusReader)\n",
      "     |  PortugueseCategorizedPlaintextCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A reader for plaintext corpora whose documents are divided into\n",
      "     |  categories based on their file identifiers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PortugueseCategorizedPlaintextCorpusReader\n",
      "     |      CategorizedPlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize the corpus reader.  Categorization arguments\n",
      "     |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      "     |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      "     |      are passed to the ``PlaintextCorpusReader`` constructor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CategorizedPlaintextCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class PropbankCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  PropbankCorpusReader(root, propfile, framefiles='', verbsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |  \n",
      "     |  Corpus reader for the propbank corpus, which augments the Penn\n",
      "     |  Treebank with information about the predicate argument structure\n",
      "     |  of every verb instance.  The corpus consists of two parts: the\n",
      "     |  predicate-argument annotations themselves, and a set of \"frameset\n",
      "     |  files\" which define the argument labels used by the annotations,\n",
      "     |  on a per-verb basis.  Each \"frameset file\" contains one or more\n",
      "     |  predicates, such as ``'turn'`` or ``'turn_on'``, each of which is\n",
      "     |  divided into coarse-grained word senses called \"rolesets\".  For\n",
      "     |  each \"roleset\", the frameset file provides descriptions of the\n",
      "     |  argument roles, along with examples.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PropbankCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, propfile, framefiles='', verbsfile=None, parse_fileid_xform=None, parse_corpus=None, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param propfile: The name of the file containing the predicate-\n",
      "     |          argument annotations (relative to ``root``).\n",
      "     |      :param framefiles: A list or regexp specifying the frameset\n",
      "     |          fileids for this corpus.\n",
      "     |      :param parse_fileid_xform: A transform that should be applied\n",
      "     |          to the fileids in this corpus.  This should be a function\n",
      "     |          of one argument (a fileid) that returns a string (the new\n",
      "     |          fileid).\n",
      "     |      :param parse_corpus: The corpus containing the parse trees\n",
      "     |          corresponding to this corpus.  These parse trees are\n",
      "     |          necessary to resolve the tree pointers used by propbank.\n",
      "     |  \n",
      "     |  instances(self, baseform=None)\n",
      "     |      :return: a corpus view that acts as a list of\n",
      "     |      ``PropBankInstance`` objects, one for each noun in the corpus.\n",
      "     |  \n",
      "     |  lines(self)\n",
      "     |      :return: a corpus view that acts as a list of strings, one for\n",
      "     |      each line in the predicate-argument annotation file.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  roleset(self, roleset_id)\n",
      "     |      :return: the xml description for the given roleset.\n",
      "     |  \n",
      "     |  rolesets(self, baseform=None)\n",
      "     |      :return: list of xml descriptions for rolesets.\n",
      "     |  \n",
      "     |  verbs(self)\n",
      "     |      :return: a corpus view that acts as a list of all verb lemmas\n",
      "     |      in this corpus (from the verbs.txt file).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ProsConsCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ProsConsCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8', **kwargs)\n",
      "     |  \n",
      "     |  Reader for the Pros and Cons sentence dataset.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import pros_cons\n",
      "     |      >>> pros_cons.sents(categories='Cons')\n",
      "     |      [['East', 'batteries', '!', 'On', '-', 'off', 'switch', 'too', 'easy',\n",
      "     |      'to', 'maneuver', '.'], ['Eats', '...', 'no', ',', 'GULPS', 'batteries'],\n",
      "     |      ...]\n",
      "     |      >>> pros_cons.words('IntegratedPros.txt')\n",
      "     |      ['Easy', 'to', 'use', ',', 'economical', '!', ...]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ProsConsCorpusReader\n",
      "     |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8', **kwargs)\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WhitespaceTokenizer`\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |      :param kwargs: additional parameters passed to CategorizedCorpusReader.\n",
      "     |  \n",
      "     |  sents(self, fileids=None, categories=None)\n",
      "     |      Return all sentences in the corpus or in the specified files/categories.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose sentences\n",
      "     |          have to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences. Each sentence is\n",
      "     |          tokenized using the specified word_tokenizer.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None, categories=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      files/categories.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :param categories: a list specifying the categories whose words have\n",
      "     |          to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  categories(self, fileids=None)\n",
      "     |      Return a list of the categories that are defined for this corpus,\n",
      "     |      or for the file(s) if it is given.\n",
      "     |  \n",
      "     |  fileids(self, categories=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that make up the given category(s) if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class RTECorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  RTECorpusReader(root, fileids, wrap_etree=False)\n",
      "     |  \n",
      "     |  Corpus reader for corpora in RTE challenges.\n",
      "     |  \n",
      "     |  This is just a wrapper around the XMLCorpusReader. See module docstring above for the expected\n",
      "     |  structure of input documents.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RTECorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  pairs(self, fileids)\n",
      "     |      Build a list of RTEPairs from a RTE corpus.\n",
      "     |      \n",
      "     |      :param fileids: a list of RTE corpus fileids\n",
      "     |      :type: list\n",
      "     |      :rtype: list(RTEPair)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ReviewsCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ReviewsCorpusReader(root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for the Customer Review Data dataset by Hu, Liu (2004).\n",
      "     |  Note: we are not applying any sentence tokenization at the moment, just word\n",
      "     |  tokenization.\n",
      "     |  \n",
      "     |      >>> from nltk.corpus import product_reviews_1\n",
      "     |      >>> camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
      "     |      >>> review = camera_reviews[0]\n",
      "     |      >>> review.sents()[0]\n",
      "     |      ['i', 'recently', 'purchased', 'the', 'canon', 'powershot', 'g3', 'and', 'am',\n",
      "     |      'extremely', 'satisfied', 'with', 'the', 'purchase', '.']\n",
      "     |      >>> review.features()\n",
      "     |      [('canon powershot g3', '+3'), ('use', '+2'), ('picture', '+2'),\n",
      "     |      ('picture quality', '+1'), ('picture quality', '+1'), ('camera', '+2'),\n",
      "     |      ('use', '+2'), ('feature', '+1'), ('picture quality', '+3'), ('use', '+1'),\n",
      "     |      ('option', '+1')]\n",
      "     |  \n",
      "     |  We can also reach the same information directly from the stream:\n",
      "     |  \n",
      "     |      >>> product_reviews_1.features('Canon_G3.txt')\n",
      "     |      [('canon powershot g3', '+3'), ('use', '+2'), ...]\n",
      "     |  \n",
      "     |  We can compute stats for specific product features:\n",
      "     |  \n",
      "     |      >>> from __future__ import division\n",
      "     |      >>> n_reviews = len([(feat,score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
      "     |      >>> tot = sum([int(score) for (feat,score) in product_reviews_1.features('Canon_G3.txt') if feat=='picture'])\n",
      "     |      >>> # We use float for backward compatibility with division in Python2.7\n",
      "     |      >>> mean = tot / n_reviews\n",
      "     |      >>> print(n_reviews, tot, mean)\n",
      "     |      15 24 1.6\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ReviewsCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), encoding='utf8')\n",
      "     |      :param root: The root directory for the corpus.\n",
      "     |      :param fileids: a list or regexp specifying the fileids in the corpus.\n",
      "     |      :param word_tokenizer: a tokenizer for breaking sentences or paragraphs\n",
      "     |          into words. Default: `WordPunctTokenizer`\n",
      "     |      :param encoding: the encoding that should be used to read the corpus.\n",
      "     |  \n",
      "     |  features(self, fileids=None)\n",
      "     |      Return a list of features. Each feature is a tuple made of the specific\n",
      "     |      item feature and the opinion strength about that feature.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          features have to be returned.\n",
      "     |      :return: all features for the item(s) in the given file(s).\n",
      "     |      :rtype: list(tuple)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :param fileids: a list or regexp specifying the fileids of the files that\n",
      "     |          have to be returned as a raw string.\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README.txt file.\n",
      "     |  \n",
      "     |  reviews(self, fileids=None)\n",
      "     |      Return all the reviews as a list of Review objects. If `fileids` is\n",
      "     |      specified, return all the reviews from each of the specified files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          reviews have to be returned.\n",
      "     |      :return: the given file(s) as a list of reviews.\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      Return all sentences in the corpus or in the specified files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          sentences have to be returned.\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded as a\n",
      "     |          list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      Return all words and punctuation symbols in the corpus or in the specified\n",
      "     |      files.\n",
      "     |      \n",
      "     |      :param fileids: a list or regexp specifying the ids of the files whose\n",
      "     |          words have to be returned.\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SemcorCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  SemcorCorpusReader(root, fileids, wordnet, lazy=True)\n",
      "     |  \n",
      "     |  Corpus reader for the SemCor Corpus.\n",
      "     |  For access to the complete XML data structure, use the ``xml()``\n",
      "     |  method.  For access to simple word lists and tagged word lists, use\n",
      "     |  ``words()``, ``sents()``, ``tagged_words()``, and ``tagged_sents()``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SemcorCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wordnet, lazy=True)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  chunk_sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded\n",
      "     |          as a list of chunks.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  chunks(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of chunks,\n",
      "     |          each of which is a list of words and punctuation symbols\n",
      "     |          that form a unit.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of sentences, each encoded\n",
      "     |          as a list of word strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_chunks(self, fileids=None, tag='pos')\n",
      "     |      :return: the given file(s) as a list of tagged chunks, represented\n",
      "     |          in tree form.\n",
      "     |      :rtype: list(Tree)\n",
      "     |      \n",
      "     |      :param tag: `'pos'` (part of speech), `'sem'` (semantic), or `'both'`\n",
      "     |          to indicate the kind of tags to include.  Semantic tags consist of\n",
      "     |          WordNet lemma IDs, plus an `'NE'` node if the chunk is a named entity\n",
      "     |          without a specific entry in WordNet.  (Named entities of type 'other'\n",
      "     |          have no lemma.  Other chunks not in WordNet have no semantic tag.\n",
      "     |          Punctuation tokens have `None` for their part of speech tag.)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tag='pos')\n",
      "     |      :return: the given file(s) as a list of sentences. Each sentence\n",
      "     |          is represented as a list of tagged chunks (in tree form).\n",
      "     |      :rtype: list(list(Tree))\n",
      "     |      \n",
      "     |      :param tag: `'pos'` (part of speech), `'sem'` (semantic), or `'both'`\n",
      "     |          to indicate the kind of tags to include.  Semantic tags consist of\n",
      "     |          WordNet lemma IDs, plus an `'NE'` node if the chunk is a named entity\n",
      "     |          without a specific entry in WordNet.  (Named entities of type 'other'\n",
      "     |          have no lemma.  Other chunks not in WordNet have no semantic tag.\n",
      "     |          Punctuation tokens have `None` for their part of speech tag.)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SensevalCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  SensevalCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SensevalCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  instances(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SentiSynset(builtins.object)\n",
      "     |  SentiSynset(pos_score, neg_score, synset)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, pos_score, neg_score, synset)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Prints just the Pos/Neg scores for now.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self)\n",
      "     |  \n",
      "     |  neg_score(self)\n",
      "     |  \n",
      "     |  obj_score(self)\n",
      "     |  \n",
      "     |  pos_score(self)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SentiWordNetCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  SentiWordNetCorpusReader(root, fileids, encoding='utf-8')\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SentiWordNetCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf-8')\n",
      "     |      Construct a new SentiWordNet Corpus Reader, using data from\n",
      "     |      the specified file.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  all_senti_synsets(self)\n",
      "     |  \n",
      "     |  senti_synset(self, *vals)\n",
      "     |  \n",
      "     |  senti_synsets(self, string, pos=None)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SinicaTreebankCorpusReader(nltk.corpus.reader.api.SyntaxCorpusReader)\n",
      "     |  SinicaTreebankCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for the sinica treebank.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SinicaTreebankCorpusReader\n",
      "     |      nltk.corpus.reader.api.SyntaxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from nltk.corpus.reader.api.SyntaxCorpusReader:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class StringCategoryCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  StringCategoryCorpusReader(root, fileids, delimiter=' ', encoding='utf8')\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StringCategoryCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, delimiter=' ', encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param delimiter: Field delimiter\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the text contents of the given fileids, as a single string.\n",
      "     |  \n",
      "     |  tuples(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SwadeshCorpusReader(WordListCorpusReader)\n",
      "     |  SwadeshCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SwadeshCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids=None)\n",
      "     |      :return: a tuple of words for the specified fileids.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SwitchboardCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  SwitchboardCorpusReader(root, tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SwitchboardCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  discourses(self)\n",
      "     |  \n",
      "     |  tagged_discourses(self, tagset=False)\n",
      "     |  \n",
      "     |  tagged_turns(self, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, tagset=None)\n",
      "     |  \n",
      "     |  turns(self)\n",
      "     |  \n",
      "     |  words(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class SyntaxCorpusReader(CorpusReader)\n",
      "     |  SyntaxCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  An abstract base class for reading corpora consisting of\n",
      "     |  syntactically parsed text.  Subclasses should define:\n",
      "     |  \n",
      "     |    - ``__init__``, which specifies the location of the corpus\n",
      "     |      and a method for detecting the sentence blocks in corpus files.\n",
      "     |    - ``_read_block``, which reads a block from the input stream.\n",
      "     |    - ``_word``, which takes a block and returns a list of list of words.\n",
      "     |    - ``_tag``, which takes a block and returns a list of list of tagged\n",
      "     |      words.\n",
      "     |    - ``_parse``, which takes a block and returns a list of parsed\n",
      "     |      sentences.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SyntaxCorpusReader\n",
      "     |      CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  parsed_sents(self, fileids=None)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TEICorpusView(nltk.corpus.reader.util.StreamBackedCorpusView)\n",
      "     |  TEICorpusView(corpus_file, tagged, group_by_sent, group_by_para, tagset=None, head_len=0, textids=None)\n",
      "     |  \n",
      "     |  A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |  it can be accessed by index, iterated over, etc.  However, the\n",
      "     |  tokens are only constructed as-needed -- the entire corpus is\n",
      "     |  never stored in memory at once.\n",
      "     |  \n",
      "     |  The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |  a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |  and a block reader.  A \"block reader\" is a function that reads\n",
      "     |  zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |  very simple example of a block reader is:\n",
      "     |  \n",
      "     |      >>> def simple_block_reader(stream):\n",
      "     |      ...     return stream.readline().split()\n",
      "     |  \n",
      "     |  This simple block reader reads a single line at a time, and\n",
      "     |  returns a single token (consisting of a string) for each\n",
      "     |  whitespace-separated substring on the line.\n",
      "     |  \n",
      "     |  When deciding how to define the block reader for a given\n",
      "     |  corpus, careful consideration should be given to the size of\n",
      "     |  blocks handled by the block reader.  Smaller block sizes will\n",
      "     |  increase the memory requirements of the corpus view's internal\n",
      "     |  data structures (by 2 integers per block).  On the other hand,\n",
      "     |  larger block sizes may decrease performance for random access to\n",
      "     |  the corpus.  (But note that larger block sizes will *not*\n",
      "     |  decrease performance for iteration.)\n",
      "     |  \n",
      "     |  Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |  index to file position, with one entry per block.  When a token\n",
      "     |  with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |  it as follows:\n",
      "     |  \n",
      "     |    1. First, it searches the toknum/filepos mapping for the token\n",
      "     |       index closest to (but less than or equal to) *i*.\n",
      "     |  \n",
      "     |    2. Then, starting at the file position corresponding to that\n",
      "     |       index, it reads one block at a time using the block reader\n",
      "     |       until it reaches the requested token.\n",
      "     |  \n",
      "     |  The toknum/filepos mapping is created lazily: it is initially\n",
      "     |  empty, but every time a new block is read, the block's\n",
      "     |  initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |  map has one entry per block.)\n",
      "     |  \n",
      "     |  In order to increase efficiency for random access patterns that\n",
      "     |  have high degrees of locality, the corpus view may cache one or\n",
      "     |  more blocks.\n",
      "     |  \n",
      "     |  :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |      object for its underlying corpus file.  This file should be\n",
      "     |      automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |      but if you wish to close it manually, use the ``close()``\n",
      "     |      method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |      closed, the file object will be automatically re-opened.\n",
      "     |  \n",
      "     |  :warning: If the contents of the file are modified during the\n",
      "     |      lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |      is undefined.\n",
      "     |  \n",
      "     |  :warning: If a unicode encoding is specified when constructing a\n",
      "     |      ``CorpusView``, then the block reader may only call\n",
      "     |      ``stream.seek()`` with offsets that have been returned by\n",
      "     |      ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |      relative offsets, or with offsets based on string lengths, may\n",
      "     |      lead to incorrect behavior.\n",
      "     |  \n",
      "     |  :ivar _block_reader: The function used to read\n",
      "     |      a single block from the underlying file stream.\n",
      "     |  :ivar _toknum: A list containing the token index of each block\n",
      "     |      that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |      token index of the first token in block ``i``.  Together\n",
      "     |      with ``_filepos``, this forms a partial mapping between token\n",
      "     |      indices and file positions.\n",
      "     |  :ivar _filepos: A list containing the file position of each block\n",
      "     |      that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |      file position of the first character in block ``i``.  Together\n",
      "     |      with ``_toknum``, this forms a partial mapping between token\n",
      "     |      indices and file positions.\n",
      "     |  :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |  :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |      or None, if the number of tokens is not yet known.\n",
      "     |  :ivar _eofpos: The character position of the last character in the\n",
      "     |      file.  This is calculated when the corpus view is initialized,\n",
      "     |      and is used to decide when the end of file has been reached.\n",
      "     |  :ivar _cache: A cache of the most recently read block.  It\n",
      "     |     is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |     start_toknum is the token index of the first token in the block;\n",
      "     |     end_toknum is the token index of the first token not in the\n",
      "     |     block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TEICorpusView\n",
      "     |      nltk.corpus.reader.util.StreamBackedCorpusView\n",
      "     |      nltk.collections.AbstractLazySequence\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, corpus_file, tagged, group_by_sent, group_by_para, tagset=None, head_len=0, textids=None)\n",
      "     |      Create a new corpus view, based on the file ``fileid``, and\n",
      "     |      read with ``block_reader``.  See the class documentation\n",
      "     |      for more information.\n",
      "     |      \n",
      "     |      :param fileid: The path to the file that is read by this\n",
      "     |          corpus view.  ``fileid`` can either be a string or a\n",
      "     |          ``PathPointer``.\n",
      "     |      \n",
      "     |      :param startpos: The file position at which the view will\n",
      "     |          start reading.  This can be used to skip over preface\n",
      "     |          sections.\n",
      "     |      \n",
      "     |      :param encoding: The unicode encoding that should be used to\n",
      "     |          read the file's contents.  If no encoding is specified,\n",
      "     |          then the file's contents will be read as a non-unicode\n",
      "     |          string (i.e., a str).\n",
      "     |  \n",
      "     |  read_block(self, stream)\n",
      "     |      Read a block from the input stream.\n",
      "     |      \n",
      "     |      :return: a block of tokens from the input stream\n",
      "     |      :rtype: list(any)\n",
      "     |      :param stream: an input stream\n",
      "     |      :type stream: stream\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.util.StreamBackedCorpusView:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |      Return a list concatenating self with other.\n",
      "     |  \n",
      "     |  __getitem__(self, i)\n",
      "     |      Return the *i* th token in the corpus file underlying this\n",
      "     |      corpus view.  Negative indices and spans are both supported.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return the number of tokens in the corpus file underlying this\n",
      "     |      corpus view.\n",
      "     |  \n",
      "     |  __mul__(self, count)\n",
      "     |      Return a list concatenating self with itself ``count`` times.\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |      Return a list concatenating other with self.\n",
      "     |  \n",
      "     |  __rmul__(self, count)\n",
      "     |      Return a list concatenating self with itself ``count`` times.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close the file stream associated with this corpus view.  This\n",
      "     |      can be useful if you are worried about running out of file\n",
      "     |      handles (although the stream should automatically be closed\n",
      "     |      upon garbage collection of the corpus view).  If the corpus\n",
      "     |      view is accessed after it is closed, it will be automatically\n",
      "     |      re-opened.\n",
      "     |  \n",
      "     |  iterate_from(self, start_tok)\n",
      "     |      Return an iterator that generates the tokens in the corpus\n",
      "     |      file underlying this corpus view, starting at the token number\n",
      "     |      ``start``.  If ``start>=len(self)``, then this iterator will\n",
      "     |      generate no tokens.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.util.StreamBackedCorpusView:\n",
      "     |  \n",
      "     |  fileid\n",
      "     |      The fileid of the file that is accessed by this view.\n",
      "     |      \n",
      "     |      :type: str or PathPointer\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.collections.AbstractLazySequence:\n",
      "     |  \n",
      "     |  __contains__(self, value)\n",
      "     |      Return true if this list contains ``value``.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a >= b.  Computed by @total_ordering from (not a < b).\n",
      "     |  \n",
      "     |  __gt__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      :raise ValueError: Corpus view objects are unhashable.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Return an iterator that generates the tokens in the corpus\n",
      "     |      file underlying this corpus view.\n",
      "     |  \n",
      "     |  __le__(self, other, NotImplemented=NotImplemented)\n",
      "     |      Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a string representation for this corpus view that is\n",
      "     |      similar to a list's representation; but if it would be more\n",
      "     |      than 60 characters long, it is truncated.\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  count(self, value)\n",
      "     |      Return the number of times this list contains ``value``.\n",
      "     |  \n",
      "     |  index(self, value, start=None, stop=None)\n",
      "     |      Return the index of the first occurrence of ``value`` in this\n",
      "     |      list that is greater than or equal to ``start`` and less than\n",
      "     |      ``stop``.  Negative start and stop values are treated like negative\n",
      "     |      slice bounds -- i.e., they count from the end of the list.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.collections.AbstractLazySequence:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TaggedCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  TaggedCorpusReader(root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x00000207D8B81558>, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  Reader for simple part-of-speech tagged corpora.  Paragraphs are\n",
      "     |  assumed to be split using blank lines.  Sentences and words can be\n",
      "     |  tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specified as parameters to the constructor.  Words are parsed\n",
      "     |  using ``nltk.tag.str2tuple``.  By default, ``'/'`` is used as the\n",
      "     |  separator.  I.e., words should have the form::\n",
      "     |  \n",
      "     |     word1/tag1 word2/tag2 word3/tag3 ...\n",
      "     |  \n",
      "     |  But custom separators may be specified as parameters to the\n",
      "     |  constructor.  Part of speech tags are case-normalized to upper\n",
      "     |  case.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, sep='/', word_tokenizer=WhitespaceTokenizer(pattern='\\\\s+', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), sent_tokenizer=RegexpTokenizer(pattern='\\n', gaps=True, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>), para_block_reader=<function read_blankline_block at 0x00000207D8B81558>, encoding='utf8', tagset=None)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_paras(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TimitCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  TimitCorpusReader(root, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for the TIMIT corpus (or any other corpus with the same\n",
      "     |  file layout and use of file formats).  The corpus root directory\n",
      "     |  should contain the following files:\n",
      "     |  \n",
      "     |    - timitdic.txt: dictionary of standard transcriptions\n",
      "     |    - spkrinfo.txt: table of speaker information\n",
      "     |  \n",
      "     |  In addition, the root directory should contain one subdirectory\n",
      "     |  for each speaker, containing three files for each utterance:\n",
      "     |  \n",
      "     |    - <utterance-id>.txt: text content of utterances\n",
      "     |    - <utterance-id>.wrd: tokenized text content of utterances\n",
      "     |    - <utterance-id>.phn: phonetic transcription of utterances\n",
      "     |    - <utterance-id>.wav: utterance sound file\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimitCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='utf8')\n",
      "     |      Construct a new TIMIT corpus reader in the given directory.\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |  \n",
      "     |  audiodata(self, utterance, start=0, end=None)\n",
      "     |  \n",
      "     |  fileids(self, filetype=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus.\n",
      "     |      \n",
      "     |      :param filetype: If specified, then ``filetype`` indicates that\n",
      "     |          only the files that have the given type should be\n",
      "     |          returned.  Accepted values are: ``txt``, ``wrd``, ``phn``,\n",
      "     |          ``wav``, or ``metadata``,\n",
      "     |  \n",
      "     |  phone_times(self, utterances=None)\n",
      "     |      offset is represented as a number of 16kHz samples!\n",
      "     |  \n",
      "     |  phone_trees(self, utterances=None)\n",
      "     |  \n",
      "     |  phones(self, utterances=None)\n",
      "     |  \n",
      "     |  play(self, utterance, start=0, end=None)\n",
      "     |      Play the given audio sample.\n",
      "     |      \n",
      "     |      :param utterance: The utterance id of the sample to play\n",
      "     |  \n",
      "     |  sent_times(self, utterances=None)\n",
      "     |  \n",
      "     |  sentid(self, utterance)\n",
      "     |  \n",
      "     |  sents(self, utterances=None)\n",
      "     |  \n",
      "     |  spkrid(self, utterance)\n",
      "     |  \n",
      "     |  spkrinfo(self, speaker)\n",
      "     |      :return: A dictionary mapping .. something.\n",
      "     |  \n",
      "     |  spkrutteranceids(self, speaker)\n",
      "     |      :return: A list of all utterances associated with a given\n",
      "     |      speaker.\n",
      "     |  \n",
      "     |  transcription_dict(self)\n",
      "     |      :return: A dictionary giving the 'standard' transcription for\n",
      "     |      each word.\n",
      "     |  \n",
      "     |  utterance(self, spkrid, sentid)\n",
      "     |  \n",
      "     |  utteranceids(self, dialect=None, sex=None, spkrid=None, sent_type=None, sentid=None)\n",
      "     |      :return: A list of the utterance identifiers for all\n",
      "     |      utterances in this corpus, or for the given speaker, dialect\n",
      "     |      region, gender, sentence type, or sentence number, if\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  wav(self, utterance, start=0, end=None)\n",
      "     |      # [xx] NOTE: This is currently broken -- we're assuming that the\n",
      "     |      # fileids are WAV fileids (aka RIFF), but they're actually NIST SPHERE\n",
      "     |      # fileids.\n",
      "     |  \n",
      "     |  word_times(self, utterances=None)\n",
      "     |  \n",
      "     |  words(self, utterances=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TimitTaggedCorpusReader(TaggedCorpusReader)\n",
      "     |  TimitTaggedCorpusReader(*args, **kwargs)\n",
      "     |  \n",
      "     |  A corpus reader for tagged sentences that are included in the TIMIT corpus.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimitTaggedCorpusReader\n",
      "     |      TaggedCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Construct a new Tagged Corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/...path to corpus.../'\n",
      "     |          >>> reader = TaggedCorpusReader(root, '.*', '.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |  \n",
      "     |  paras(self)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  tagged_paras(self)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      "     |      :rtype: list(list(list(tuple(str,str))))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from TaggedCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  tagged_sents(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(list(tuple(str,str)))\n",
      "     |  \n",
      "     |  tagged_words(self, fileids=None, tagset=None)\n",
      "     |      :return: the given file(s) as a list of tagged\n",
      "     |          words and punctuation symbols, encoded as tuples\n",
      "     |          ``(word,tag)``.\n",
      "     |      :rtype: list(tuple(str,str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class ToolboxCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  ToolboxCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  A base class for \"corpus reader\" classes, each of which can be\n",
      "     |  used to read a specific corpus format.  Each individual corpus\n",
      "     |  reader instance is used to read a specific corpus, consisting of\n",
      "     |  one or more files under a common root directory.  Each file is\n",
      "     |  identified by its ``file identifier``, which is the relative path\n",
      "     |  to the file from the root directory.\n",
      "     |  \n",
      "     |  A separate subclass is defined for each corpus format.  These\n",
      "     |  subclasses define one or more methods that provide 'views' on the\n",
      "     |  corpus contents, such as ``words()`` (for a list of words) and\n",
      "     |  ``parsed_sents()`` (for a list of parsed sentences).  Called with\n",
      "     |  no arguments, these methods will return the contents of the entire\n",
      "     |  corpus.  For most corpora, these methods define one or more\n",
      "     |  selection arguments, such as ``fileids`` or ``categories``, which can\n",
      "     |  be used to select which portion of the corpus should be returned.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ToolboxCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  entries(self, fileids, **kwargs)\n",
      "     |      # should probably be done lazily:\n",
      "     |  \n",
      "     |  fields(self, fileids, strip=True, unwrap=True, encoding='utf8', errors='strict', unicode_fields=None)\n",
      "     |  \n",
      "     |  raw(self, fileids)\n",
      "     |  \n",
      "     |  words(self, fileids, key='lx')\n",
      "     |  \n",
      "     |  xml(self, fileids, key=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class TwitterCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  TwitterCorpusReader(root, fileids=None, word_tokenizer=<nltk.tokenize.casual.TweetTokenizer object at 0x00000207D8CC11C8>, encoding='utf8')\n",
      "     |  \n",
      "     |  Reader for corpora that consist of Tweets represented as a list of line-delimited JSON.\n",
      "     |  \n",
      "     |  Individual Tweets can be tokenized using the default tokenizer, or by a\n",
      "     |  custom tokenizer specified as a parameter to the constructor.\n",
      "     |  \n",
      "     |  Construct a new Tweet corpus reader for a set of documents\n",
      "     |  located at the given root directory.\n",
      "     |  \n",
      "     |  If you made your own tweet collection in a directory called\n",
      "     |  `twitter-files`, then you can initialise the reader as::\n",
      "     |  \n",
      "     |      from nltk.corpus import TwitterCorpusReader\n",
      "     |      reader = TwitterCorpusReader(root='/path/to/twitter-files', '.*\\.json')\n",
      "     |  \n",
      "     |  However, the recommended approach is to set the relevant directory as the\n",
      "     |  value of the environmental variable `TWITTER`, and then invoke the reader\n",
      "     |  as follows::\n",
      "     |  \n",
      "     |     root = os.environ['TWITTER']\n",
      "     |     reader = TwitterCorpusReader(root, '.*\\.json')\n",
      "     |  \n",
      "     |  If you want to work directly with the raw Tweets, the `json` library can\n",
      "     |  be used::\n",
      "     |  \n",
      "     |     import json\n",
      "     |     for tweet in reader.docs():\n",
      "     |         print(json.dumps(tweet, indent=1, sort_keys=True))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TwitterCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids=None, word_tokenizer=<nltk.tokenize.casual.TweetTokenizer object at 0x00000207D8CC11C8>, encoding='utf8')\n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      \n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      \n",
      "     |      :param word_tokenizer: Tokenizer for breaking the text of Tweets into\n",
      "     |      smaller units, including but not limited to words.\n",
      "     |  \n",
      "     |  docs(self, fileids=None)\n",
      "     |      Returns the full Tweet objects, as specified by `Twitter\n",
      "     |      documentation on Tweets\n",
      "     |      <https://dev.twitter.com/docs/platform-objects/tweets>`_\n",
      "     |      \n",
      "     |      :return: the given file(s) as a list of dictionaries deserialised\n",
      "     |      from JSON.\n",
      "     |      :rtype: list(dict)\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      Return the corpora in their raw form.\n",
      "     |  \n",
      "     |  strings(self, fileids=None)\n",
      "     |      Returns only the text content of Tweets in the file(s)\n",
      "     |      \n",
      "     |      :return: the given file(s) as a list of Tweets.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  tokenized(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of the text content of Tweets as\n",
      "     |      as a list of words, screenanames, hashtags, URLs and punctuation symbols.\n",
      "     |      \n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class UdhrCorpusReader(nltk.corpus.reader.plaintext.PlaintextCorpusReader)\n",
      "     |  UdhrCorpusReader(root='udhr')\n",
      "     |  \n",
      "     |  Reader for corpora that consist of plaintext documents.  Paragraphs\n",
      "     |  are assumed to be split using blank lines.  Sentences and words can\n",
      "     |  be tokenized using the default tokenizers, or by custom tokenizers\n",
      "     |  specificed as parameters to the constructor.\n",
      "     |  \n",
      "     |  This corpus reader can be customized (e.g., to skip preface\n",
      "     |  sections of specific document formats) by creating a subclass and\n",
      "     |  overriding the ``CorpusView`` class variable.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UdhrCorpusReader\n",
      "     |      nltk.corpus.reader.plaintext.PlaintextCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root='udhr')\n",
      "     |      Construct a new plaintext corpus reader for a set of documents\n",
      "     |      located at the given root directory.  Example usage:\n",
      "     |      \n",
      "     |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      "     |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      "     |      \n",
      "     |      :param root: The root directory for this corpus.\n",
      "     |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      "     |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      "     |          paragraphs into words.\n",
      "     |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      "     |          into words.\n",
      "     |      :param para_block_reader: The block reader used to divide the\n",
      "     |          corpus into paragraph blocks.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ENCODINGS = [('.*-Latin1$', 'latin-1'), ('.*-Hebrew$', 'hebrew'), ('.*...\n",
      "     |  \n",
      "     |  SKIP = {'Amharic-Afenegus6..60375', 'Armenian-DallakHelv', 'Azeri_Azer...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.plaintext.PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  paras(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          paragraphs, each encoded as a list of sentences, which are\n",
      "     |          in turn encoded as lists of word strings.\n",
      "     |      :rtype: list(list(list(str)))\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |      :return: the given file(s) as a single string.\n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  sents(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of\n",
      "     |          sentences or utterances, each encoded as a list of word\n",
      "     |          strings.\n",
      "     |      :rtype: list(list(str))\n",
      "     |  \n",
      "     |  words(self, fileids=None)\n",
      "     |      :return: the given file(s) as a list of words\n",
      "     |          and punctuation symbols.\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from nltk.corpus.reader.plaintext.PlaintextCorpusReader:\n",
      "     |  \n",
      "     |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "     |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      "     |      it can be accessed by index, iterated over, etc.  However, the\n",
      "     |      tokens are only constructed as-needed -- the entire corpus is\n",
      "     |      never stored in memory at once.\n",
      "     |      \n",
      "     |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      "     |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      "     |      and a block reader.  A \"block reader\" is a function that reads\n",
      "     |      zero or more tokens from a stream, and returns them as a list.  A\n",
      "     |      very simple example of a block reader is:\n",
      "     |      \n",
      "     |          >>> def simple_block_reader(stream):\n",
      "     |          ...     return stream.readline().split()\n",
      "     |      \n",
      "     |      This simple block reader reads a single line at a time, and\n",
      "     |      returns a single token (consisting of a string) for each\n",
      "     |      whitespace-separated substring on the line.\n",
      "     |      \n",
      "     |      When deciding how to define the block reader for a given\n",
      "     |      corpus, careful consideration should be given to the size of\n",
      "     |      blocks handled by the block reader.  Smaller block sizes will\n",
      "     |      increase the memory requirements of the corpus view's internal\n",
      "     |      data structures (by 2 integers per block).  On the other hand,\n",
      "     |      larger block sizes may decrease performance for random access to\n",
      "     |      the corpus.  (But note that larger block sizes will *not*\n",
      "     |      decrease performance for iteration.)\n",
      "     |      \n",
      "     |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      "     |      index to file position, with one entry per block.  When a token\n",
      "     |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      "     |      it as follows:\n",
      "     |      \n",
      "     |        1. First, it searches the toknum/filepos mapping for the token\n",
      "     |           index closest to (but less than or equal to) *i*.\n",
      "     |      \n",
      "     |        2. Then, starting at the file position corresponding to that\n",
      "     |           index, it reads one block at a time using the block reader\n",
      "     |           until it reaches the requested token.\n",
      "     |      \n",
      "     |      The toknum/filepos mapping is created lazily: it is initially\n",
      "     |      empty, but every time a new block is read, the block's\n",
      "     |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      "     |      map has one entry per block.)\n",
      "     |      \n",
      "     |      In order to increase efficiency for random access patterns that\n",
      "     |      have high degrees of locality, the corpus view may cache one or\n",
      "     |      more blocks.\n",
      "     |      \n",
      "     |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      "     |          object for its underlying corpus file.  This file should be\n",
      "     |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      "     |          but if you wish to close it manually, use the ``close()``\n",
      "     |          method.  If you access a ``CorpusView``'s items after it has been\n",
      "     |          closed, the file object will be automatically re-opened.\n",
      "     |      \n",
      "     |      :warning: If the contents of the file are modified during the\n",
      "     |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      "     |          is undefined.\n",
      "     |      \n",
      "     |      :warning: If a unicode encoding is specified when constructing a\n",
      "     |          ``CorpusView``, then the block reader may only call\n",
      "     |          ``stream.seek()`` with offsets that have been returned by\n",
      "     |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      "     |          relative offsets, or with offsets based on string lengths, may\n",
      "     |          lead to incorrect behavior.\n",
      "     |      \n",
      "     |      :ivar _block_reader: The function used to read\n",
      "     |          a single block from the underlying file stream.\n",
      "     |      :ivar _toknum: A list containing the token index of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          token index of the first token in block ``i``.  Together\n",
      "     |          with ``_filepos``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _filepos: A list containing the file position of each block\n",
      "     |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      "     |          file position of the first character in block ``i``.  Together\n",
      "     |          with ``_toknum``, this forms a partial mapping between token\n",
      "     |          indices and file positions.\n",
      "     |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      "     |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      "     |          or None, if the number of tokens is not yet known.\n",
      "     |      :ivar _eofpos: The character position of the last character in the\n",
      "     |          file.  This is calculated when the corpus view is initialized,\n",
      "     |          and is used to decide when the end of file has been reached.\n",
      "     |      :ivar _cache: A cache of the most recently read block.  It\n",
      "     |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      "     |         start_toknum is the token index of the first token in the block;\n",
      "     |         end_toknum is the token index of the first token not in the\n",
      "     |         block; and tokens is a list of the tokens in the block.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class UnicharsCorpusReader(WordListCorpusReader)\n",
      "     |  UnicharsCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  This class is used to read lists of characters from the Perl Unicode\n",
      "     |  Properties (see http://perldoc.perl.org/perluniprops.html).\n",
      "     |  The files in the perluniprop.zip are extracted using the Unicode::Tussle\n",
      "     |  module from http://search.cpan.org/~bdfoy/Unicode-Tussle-1.11/lib/Unicode/Tussle.pm\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnicharsCorpusReader\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  chars(self, category=None, fileids=None)\n",
      "     |      This module returns a list of characters from  the Perl Unicode Properties.\n",
      "     |      They are very useful when porting Perl tokenizers to Python.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import perluniprops as pup\n",
      "     |      >>> pup.chars('Open_Punctuation')[:5] == [u'(', u'[', u'{', u'', u'']\n",
      "     |      True\n",
      "     |      >>> pup.chars('Currency_Symbol')[:5] == [u'$', u'', u'', u'', u'']\n",
      "     |      True\n",
      "     |      >>> pup.available_categories\n",
      "     |      ['Close_Punctuation', 'Currency_Symbol', 'IsAlnum', 'IsAlpha', 'IsLower', 'IsN', 'IsSc', 'IsSo', 'IsUpper', 'Line_Separator', 'Number', 'Open_Punctuation', 'Punctuation', 'Separator', 'Symbol']\n",
      "     |      \n",
      "     |      :return: a list of characters given the specific unicode character category\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  available_categories = ['Close_Punctuation', 'Currency_Symbol', 'IsAln...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from WordListCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class VerbnetCorpusReader(nltk.corpus.reader.xmldocs.XMLCorpusReader)\n",
      "     |  VerbnetCorpusReader(root, fileids, wrap_etree=False)\n",
      "     |  \n",
      "     |  An NLTK interface to the VerbNet verb lexicon.\n",
      "     |  \n",
      "     |  From the VerbNet site: \"VerbNet (VN) (Kipper-Schuler 2006) is the largest\n",
      "     |  on-line verb lexicon currently available for English. It is a hierarchical\n",
      "     |  domain-independent, broad-coverage verb lexicon with mappings to other\n",
      "     |  lexical resources such as WordNet (Miller, 1990; Fellbaum, 1998), XTAG\n",
      "     |  (XTAG Research Group, 2001), and FrameNet (Baker et al., 1998).\"\n",
      "     |  \n",
      "     |  For details about VerbNet see:\n",
      "     |  https://verbs.colorado.edu/~mpalmer/projects/verbnet.html\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VerbnetCorpusReader\n",
      "     |      nltk.corpus.reader.xmldocs.XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  classids(self, lemma=None, wordnetid=None, fileid=None, classid=None)\n",
      "     |      Return a list of the VerbNet class identifiers.  If a file\n",
      "     |      identifier is specified, then return only the VerbNet class\n",
      "     |      identifiers for classes (and subclasses) defined by that file.\n",
      "     |      If a lemma is specified, then return only VerbNet class\n",
      "     |      identifiers for classes that contain that lemma as a member.\n",
      "     |      If a wordnetid is specified, then return only identifiers for\n",
      "     |      classes that contain that wordnetid as a member.  If a classid\n",
      "     |      is specified, then return only identifiers for subclasses of\n",
      "     |      the specified VerbNet class.\n",
      "     |      If nothing is specified, return all classids within VerbNet\n",
      "     |  \n",
      "     |  fileids(self, vnclass_ids=None)\n",
      "     |      Return a list of fileids that make up this corpus.  If\n",
      "     |      ``vnclass_ids`` is specified, then return the fileids that make\n",
      "     |      up the specified VerbNet class(es).\n",
      "     |  \n",
      "     |  frames(self, vnclass)\n",
      "     |      Given a VerbNet class, this method returns VerbNet frames\n",
      "     |      \n",
      "     |      The members returned are:\n",
      "     |      1) Example\n",
      "     |      2) Description\n",
      "     |      3) Syntax\n",
      "     |      4) Semantics\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |      :return: frames - a list of frame dictionaries\n",
      "     |  \n",
      "     |  lemmas(self, vnclass=None)\n",
      "     |      Return a list of all verb lemmas that appear in any class, or\n",
      "     |      in the ``classid`` if specified.\n",
      "     |  \n",
      "     |  longid(self, shortid)\n",
      "     |      Returns longid of a VerbNet class\n",
      "     |      \n",
      "     |      Given a short VerbNet class identifier (eg '37.10'), map it\n",
      "     |      to a long id (eg 'confess-37.10').  If ``shortid`` is already a\n",
      "     |      long id, then return it as-is\n",
      "     |  \n",
      "     |  pprint(self, vnclass)\n",
      "     |      Returns pretty printed version of a VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given VerbNet class.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |      containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  pprint_frames(self, vnclass, indent='')\n",
      "     |      Returns pretty version of all frames in a VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the list of frames within the VerbNet class.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  pprint_members(self, vnclass, indent='')\n",
      "     |      Returns pretty printed version of members in a VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given VerbNet class's member verbs.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  pprint_subclasses(self, vnclass, indent='')\n",
      "     |      Returns pretty printed version of subclasses of VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given VerbNet class's subclasses.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  pprint_themroles(self, vnclass, indent='')\n",
      "     |      Returns pretty printed version of thematic roles in a VerbNet class\n",
      "     |      \n",
      "     |      Return a string containing a pretty-printed representation of\n",
      "     |      the given VerbNet class's thematic roles.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |  \n",
      "     |  shortid(self, longid)\n",
      "     |      Returns shortid of a VerbNet class\n",
      "     |      \n",
      "     |      Given a long VerbNet class identifier (eg 'confess-37.10'),\n",
      "     |      map it to a short id (eg '37.10').  If ``longid`` is already a\n",
      "     |      short id, then return it as-is.\n",
      "     |  \n",
      "     |  subclasses(self, vnclass)\n",
      "     |      Returns subclass ids, if any exist\n",
      "     |      \n",
      "     |      Given a VerbNet class, this method returns subclass ids (if they exist)\n",
      "     |      in a list of strings.\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |      :return: list of subclasses\n",
      "     |  \n",
      "     |  themroles(self, vnclass)\n",
      "     |      Returns thematic roles participating in a VerbNet class\n",
      "     |      \n",
      "     |      Members returned as part of roles are-\n",
      "     |      1) Type\n",
      "     |      2) Modifiers\n",
      "     |      \n",
      "     |      :param vnclass: A VerbNet class identifier; or an ElementTree\n",
      "     |          containing the xml contents of a VerbNet class.\n",
      "     |      :return: themroles: A list of thematic roles in the VerbNet class\n",
      "     |  \n",
      "     |  vnclass(self, fileid_or_classid)\n",
      "     |      Returns VerbNet class ElementTree\n",
      "     |      \n",
      "     |      Return an ElementTree containing the xml for the specified\n",
      "     |      VerbNet class.\n",
      "     |      \n",
      "     |      :param fileid_or_classid: An identifier specifying which class\n",
      "     |          should be returned.  Can be a file identifier (such as\n",
      "     |          ``'put-9.1.xml'``), or a VerbNet class identifier (such as\n",
      "     |          ``'put-9.1'``) or a short VerbNet class identifier (such as\n",
      "     |          ``'9.1'``).\n",
      "     |  \n",
      "     |  wordnetids(self, vnclass=None)\n",
      "     |      Return a list of all wordnet identifiers that appear in any\n",
      "     |      class, or in ``classid`` if specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.xmldocs.XMLCorpusReader:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordListCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  WordListCorpusReader(root, fileids, encoding='utf8', tagset=None)\n",
      "     |  \n",
      "     |  List of words, one per line.  Blank lines are ignored.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordListCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileids=None, ignore_lines_startswith='\\n')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, encoding='utf8', tagset=None)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordNetCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  WordNetCorpusReader(root, omw_reader)\n",
      "     |  \n",
      "     |  A corpus reader used to access wordnet or its variants.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordNetCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, omw_reader)\n",
      "     |      Construct a new wordnet corpus reader, with the given root\n",
      "     |      directory.\n",
      "     |  \n",
      "     |  all_lemma_names(self, pos=None, lang='eng')\n",
      "     |      Return all lemma names for all synsets for the given\n",
      "     |      part of speech tag and language or languages. If pos is\n",
      "     |      not specified, all synsets for all parts of speech will\n",
      "     |      be used.\n",
      "     |  \n",
      "     |  all_synsets(self, pos=None)\n",
      "     |      Iterate over all synsets with a given part of speech tag.\n",
      "     |      If no pos is specified, all synsets for all parts of speech\n",
      "     |      will be loaded.\n",
      "     |  \n",
      "     |  citation(self, lang='omw')\n",
      "     |      Return the contents of citation.bib file (for omw)\n",
      "     |      use lang=lang to get the citation for an individual language\n",
      "     |  \n",
      "     |  custom_lemmas(self, tab_file, lang)\n",
      "     |      Reads a custom tab file containing mappings of lemmas in the given\n",
      "     |      language to Princeton WordNet 3.0 synset offsets, allowing NLTK's\n",
      "     |      WordNet functions to then be used with that language.\n",
      "     |      \n",
      "     |      See the \"Tab files\" section at http://compling.hss.ntu.edu.sg/omw/ for\n",
      "     |      documentation on the Multilingual WordNet tab file format.\n",
      "     |      \n",
      "     |      :param tab_file: Tab file as a file or file-like object\n",
      "     |      :type  lang str\n",
      "     |      :param lang ISO 639-3 code of the language of the tab file\n",
      "     |  \n",
      "     |  get_version(self)\n",
      "     |  \n",
      "     |  ic(self, corpus, weight_senses_equally=False, smoothing=1.0)\n",
      "     |      Creates an information content lookup dictionary from a corpus.\n",
      "     |      \n",
      "     |      :type corpus: CorpusReader\n",
      "     |      :param corpus: The corpus from which we create an information\n",
      "     |      content dictionary.\n",
      "     |      :type weight_senses_equally: bool\n",
      "     |      :param weight_senses_equally: If this is True, gives all\n",
      "     |      possible senses equal weight rather than dividing by the\n",
      "     |      number of possible senses.  (If a word has 3 synses, each\n",
      "     |      sense gets 0.3333 per appearance when this is False, 1.0 when\n",
      "     |      it is true.)\n",
      "     |      :param smoothing: How much do we smooth synset counts (default is 1.0)\n",
      "     |      :type smoothing: float\n",
      "     |      :return: An information content dictionary\n",
      "     |  \n",
      "     |  jcn_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Jiang-Conrath Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node) and that of the two input Synsets. The relationship is\n",
      "     |      given by the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type  ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects.\n",
      "     |  \n",
      "     |  langs(self)\n",
      "     |      return a list of languages supported by Multilingual Wordnet\n",
      "     |  \n",
      "     |  lch_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Leacock Chodorow Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      shortest path that connects the senses (as above) and the maximum depth\n",
      "     |      of the taxonomy in which the senses occur. The relationship is given as\n",
      "     |      -log(p/2d) where p is the shortest path length and d is the taxonomy\n",
      "     |      depth.\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      "     |          normally greater than 0. None is returned if no connecting path\n",
      "     |          could be found. If a ``Synset`` is compared with itself, the\n",
      "     |          maximum score is returned, which varies depending on the taxonomy\n",
      "     |          depth.\n",
      "     |  \n",
      "     |  lemma(self, name, lang='eng')\n",
      "     |      Return lemma object that matches the name\n",
      "     |  \n",
      "     |  lemma_count(self, lemma)\n",
      "     |      Return the frequency count for this Lemma\n",
      "     |  \n",
      "     |  lemma_from_key(self, key)\n",
      "     |  \n",
      "     |  lemmas(self, lemma, pos=None, lang='eng')\n",
      "     |      Return all Lemma objects with a name matching the specified lemma\n",
      "     |      name and part of speech tag. Matches any part of speech tag if none is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  license(self, lang='eng')\n",
      "     |      Return the contents of LICENSE (for omw)\n",
      "     |      use lang=lang to get the license for an individual language\n",
      "     |  \n",
      "     |  lin_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Lin Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node) and that of the two input Synsets. The relationship is\n",
      "     |      given by the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
      "     |      \n",
      "     |      :type other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects, in the range 0 to 1.\n",
      "     |  \n",
      "     |  morphy(self, form, pos=None, check_exceptions=True)\n",
      "     |      Find a possible base form for the given form, with the given\n",
      "     |      part of speech, by checking WordNet's list of exceptional\n",
      "     |      forms, and by recursively stripping affixes for this part of\n",
      "     |      speech until a form in WordNet is found.\n",
      "     |      \n",
      "     |      >>> from nltk.corpus import wordnet as wn\n",
      "     |      >>> print(wn.morphy('dogs'))\n",
      "     |      dog\n",
      "     |      >>> print(wn.morphy('churches'))\n",
      "     |      church\n",
      "     |      >>> print(wn.morphy('aardwolves'))\n",
      "     |      aardwolf\n",
      "     |      >>> print(wn.morphy('abaci'))\n",
      "     |      abacus\n",
      "     |      >>> wn.morphy('hardrock', wn.ADV)\n",
      "     |      >>> print(wn.morphy('book', wn.NOUN))\n",
      "     |      book\n",
      "     |      >>> wn.morphy('book', wn.ADJ)\n",
      "     |  \n",
      "     |  of2ss(self, of)\n",
      "     |      take an id and return the synsets\n",
      "     |  \n",
      "     |  path_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Path Distance Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      shortest path that connects the senses in the is-a (hypernym/hypnoym)\n",
      "     |      taxonomy. The score is in the range 0 to 1, except in those cases where\n",
      "     |      a path cannot be found (will only be true for verbs as there are many\n",
      "     |      distinct verb taxonomies), in which case None is returned. A score of\n",
      "     |      1 represents identity i.e. comparing a sense with itself will return 1.\n",
      "     |      \n",
      "     |      :type other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      "     |          normally between 0 and 1. None is returned if no connecting path\n",
      "     |          could be found. 1 is returned if a ``Synset`` is compared with\n",
      "     |          itself.\n",
      "     |  \n",
      "     |  readme(self, lang='omw')\n",
      "     |      Return the contents of README (for omw)\n",
      "     |      use lang=lang to get the readme for an individual language\n",
      "     |  \n",
      "     |  res_similarity(self, synset1, synset2, ic, verbose=False)\n",
      "     |      Resnik Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      "     |      ancestor node).\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type ic: dict\n",
      "     |      :param ic: an information content object (as returned by\n",
      "     |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects. Synsets whose LCS is the root node of the taxonomy will\n",
      "     |          have a score of 0 (e.g. N['dog'][0] and N['table'][0]).\n",
      "     |  \n",
      "     |  ss2of(self, ss, lang=None)\n",
      "     |      return the ID of the synset\n",
      "     |  \n",
      "     |  synset(self, name)\n",
      "     |      #############################################################\n",
      "     |      # Loading Synsets\n",
      "     |      #############################################################\n",
      "     |  \n",
      "     |  synset_from_pos_and_offset(self, pos, offset)\n",
      "     |  \n",
      "     |  synset_from_sense_key(self, sense_key)\n",
      "     |      Retrieves synset based on a given sense_key. Sense keys can be\n",
      "     |      obtained from lemma.key()\n",
      "     |      \n",
      "     |      From https://wordnet.princeton.edu/documentation/senseidx5wn:\n",
      "     |      A sense_key is represented as:\n",
      "     |          lemma % lex_sense (e.g. 'dog%1:18:01::')\n",
      "     |      where lex_sense is encoded as:\n",
      "     |          ss_type:lex_filenum:lex_id:head_word:head_id\n",
      "     |      \n",
      "     |      lemma:       ASCII text of word/collocation, in lower case\n",
      "     |      ss_type:     synset type for the sense (1 digit int)\n",
      "     |                   The synset type is encoded as follows:\n",
      "     |                   1    NOUN\n",
      "     |                   2    VERB\n",
      "     |                   3    ADJECTIVE\n",
      "     |                   4    ADVERB\n",
      "     |                   5    ADJECTIVE SATELLITE\n",
      "     |      lex_filenum: name of lexicographer file containing the synset for the sense (2 digit int)\n",
      "     |      lex_id:      when paired with lemma, uniquely identifies a sense in the lexicographer file (2 digit int)\n",
      "     |      head_word:   lemma of the first word in satellite's head synset\n",
      "     |                   Only used if sense is in an adjective satellite synset\n",
      "     |      head_id:     uniquely identifies sense in a lexicographer file when paired with head_word\n",
      "     |                   Only used if head_word is present (2 digit int)\n",
      "     |  \n",
      "     |  synsets(self, lemma, pos=None, lang='eng', check_exceptions=True)\n",
      "     |      Load all synsets with a given lemma and part of speech tag.\n",
      "     |      If no pos is specified, all synsets for all parts of speech\n",
      "     |      will be loaded.\n",
      "     |      If lang is specified, all the synsets associated with the lemma name\n",
      "     |      of that language will be returned.\n",
      "     |  \n",
      "     |  words(self, lang='eng')\n",
      "     |      return lemmas of the given language as list of words\n",
      "     |  \n",
      "     |  wup_similarity(self, synset1, synset2, verbose=False, simulate_root=True)\n",
      "     |      Wu-Palmer Similarity:\n",
      "     |      Return a score denoting how similar two word senses are, based on the\n",
      "     |      depth of the two senses in the taxonomy and that of their Least Common\n",
      "     |      Subsumer (most specific ancestor node). Previously, the scores computed\n",
      "     |      by this implementation did _not_ always agree with those given by\n",
      "     |      Pedersen's Perl implementation of WordNet Similarity. However, with\n",
      "     |      the addition of the simulate_root flag (see below), the score for\n",
      "     |      verbs now almost always agree but not always for nouns.\n",
      "     |      \n",
      "     |      The LCS does not necessarily feature in the shortest path connecting\n",
      "     |      the two senses, as it is by definition the common ancestor deepest in\n",
      "     |      the taxonomy, not closest to the two senses. Typically, however, it\n",
      "     |      will so feature. Where multiple candidates for the LCS exist, that\n",
      "     |      whose shortest path to the root node is the longest will be selected.\n",
      "     |      Where the LCS has multiple paths to the root, the longer path is used\n",
      "     |      for the purposes of the calculation.\n",
      "     |      \n",
      "     |      :type  other: Synset\n",
      "     |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      "     |      :type simulate_root: bool\n",
      "     |      :param simulate_root: The various verb taxonomies do not\n",
      "     |          share a single root which disallows this metric from working for\n",
      "     |          synsets that are not connected. This flag (True by default)\n",
      "     |          creates a fake root that connects all the taxonomies. Set it\n",
      "     |          to false to disable this behavior. For the noun taxonomy,\n",
      "     |          there is usually a default root except for WordNet version 1.6.\n",
      "     |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      "     |          as well.\n",
      "     |      :return: A float score denoting the similarity of the two ``Synset``\n",
      "     |          objects, normally greater than zero. If no connecting path between\n",
      "     |          the two senses can be found, None is returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ADJ = 'a'\n",
      "     |  \n",
      "     |  ADJ_SAT = 's'\n",
      "     |  \n",
      "     |  ADV = 'r'\n",
      "     |  \n",
      "     |  MORPHOLOGICAL_SUBSTITUTIONS = {'a': [('er', ''), ('est', ''), ('er', '...\n",
      "     |  \n",
      "     |  NOUN = 'n'\n",
      "     |  \n",
      "     |  VERB = 'v'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class WordNetICCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  WordNetICCorpusReader(root, fileids)\n",
      "     |  \n",
      "     |  A corpus reader for the WordNet information content corpus.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WordNetICCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  ic(self, icfile)\n",
      "     |      Load an information content file from the wordnet_ic corpus\n",
      "     |      and return a dictionary.  This dictionary has just two keys,\n",
      "     |      NOUN and VERB, whose values are dictionaries that map from\n",
      "     |      synsets to information content values.\n",
      "     |      \n",
      "     |      :type icfile: str\n",
      "     |      :param icfile: The name of the wordnet_ic file (e.g. \"ic-brown.dat\")\n",
      "     |      :return: An information content dictionary\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class XMLCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  XMLCorpusReader(root, fileids, wrap_etree=False)\n",
      "     |  \n",
      "     |  Corpus reader for corpora whose documents are xml files.\n",
      "     |  \n",
      "     |  Note that the ``XMLCorpusReader`` constructor does not take an\n",
      "     |  ``encoding`` argument, because the unicode encoding is specified by\n",
      "     |  the XML files themselves.  See the XML specs for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XMLCorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, fileids, wrap_etree=False)\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  raw(self, fileids=None)\n",
      "     |  \n",
      "     |  words(self, fileid=None)\n",
      "     |      Returns all of the words and punctuation symbols in the specified file\n",
      "     |      that were in text nodes -- ie, tags are ignored. Like the xml() method,\n",
      "     |      fileid can only specify one file.\n",
      "     |      \n",
      "     |      :return: the given file's text nodes as a list of words and punctuation symbols\n",
      "     |      :rtype: list(str)\n",
      "     |  \n",
      "     |  xml(self, fileid=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  fileids(self)\n",
      "     |      Return a list of file identifiers for the fileids that make up\n",
      "     |      this corpus.\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "    \n",
      "    class YCOECorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      "     |  YCOECorpusReader(root, encoding='utf8')\n",
      "     |  \n",
      "     |  Corpus reader for the York-Toronto-Helsinki Parsed Corpus of Old\n",
      "     |  English Prose (YCOE), a 1.5 million word syntactically-annotated\n",
      "     |  corpus of Old English prose texts.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      YCOECorpusReader\n",
      "     |      nltk.corpus.reader.api.CorpusReader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root, encoding='utf8')\n",
      "     |      :type root: PathPointer or str\n",
      "     |      :param root: A path pointer identifying the root directory for\n",
      "     |          this corpus.  If a string is specified, then it will be\n",
      "     |          converted to a ``PathPointer`` automatically.\n",
      "     |      :param fileids: A list of the files that make up this corpus.\n",
      "     |          This list can either be specified explicitly, as a list of\n",
      "     |          strings; or implicitly, as a regular expression over file\n",
      "     |          paths.  The absolute path for each file will be constructed\n",
      "     |          by joining the reader's root to each file name.\n",
      "     |      :param encoding: The default unicode encoding for the files\n",
      "     |          that make up the corpus.  The value of ``encoding`` can be any\n",
      "     |          of the following:\n",
      "     |          - A string: ``encoding`` is the encoding name for all files.\n",
      "     |          - A dictionary: ``encoding[file_id]`` is the encoding\n",
      "     |            name for the file whose identifier is ``file_id``.  If\n",
      "     |            ``file_id`` is not in ``encoding``, then the file\n",
      "     |            contents will be processed using non-unicode byte strings.\n",
      "     |          - A list: ``encoding`` should be a list of ``(regexp, encoding)``\n",
      "     |            tuples.  The encoding for a file whose identifier is ``file_id``\n",
      "     |            will be the ``encoding`` value for the first tuple whose\n",
      "     |            ``regexp`` matches the ``file_id``.  If no tuple's ``regexp``\n",
      "     |            matches the ``file_id``, the file contents will be processed\n",
      "     |            using non-unicode byte strings.\n",
      "     |          - None: the file contents of all files will be\n",
      "     |            processed using non-unicode byte strings.\n",
      "     |      :param tagset: The name of the tagset used by this corpus, to be used\n",
      "     |            for normalizing or converting the POS tags returned by the\n",
      "     |            tagged_...() methods.\n",
      "     |  \n",
      "     |  documents(self, fileids=None)\n",
      "     |      Return a list of document identifiers for all documents in\n",
      "     |      this corpus, or for the documents with the given file(s) if\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  fileids(self, documents=None)\n",
      "     |      Return a list of file identifiers for the files that make up\n",
      "     |      this corpus, or that store the given document(s) if specified.\n",
      "     |  \n",
      "     |  paras(self, documents=None)\n",
      "     |  \n",
      "     |  parsed_sents(self, documents=None)\n",
      "     |  \n",
      "     |  sents(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_paras(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_sents(self, documents=None)\n",
      "     |  \n",
      "     |  tagged_words(self, documents=None)\n",
      "     |  \n",
      "     |  words(self, documents=None)\n",
      "     |      # Delegate to one of our two sub-readers:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  abspath(self, fileid)\n",
      "     |      Return the absolute path for the given file.\n",
      "     |      \n",
      "     |      :type fileid: str\n",
      "     |      :param fileid: The file identifier for the file whose path\n",
      "     |          should be returned.\n",
      "     |      :rtype: PathPointer\n",
      "     |  \n",
      "     |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      "     |      Return a list of the absolute paths for all fileids in this corpus;\n",
      "     |      or for the given list of fileids, if specified.\n",
      "     |      \n",
      "     |      :type fileids: None or str or list\n",
      "     |      :param fileids: Specifies the set of fileids for which paths should\n",
      "     |          be returned.  Can be None, for all fileids; a list of\n",
      "     |          file identifiers, for a specified set of fileids; or a single\n",
      "     |          file identifier, for a single file.  Note that the return\n",
      "     |          value is always a list of paths, even if ``fileids`` is a\n",
      "     |          single file identifier.\n",
      "     |      \n",
      "     |      :param include_encoding: If true, then return a list of\n",
      "     |          ``(path_pointer, encoding)`` tuples.\n",
      "     |      \n",
      "     |      :rtype: list(PathPointer)\n",
      "     |  \n",
      "     |  citation(self)\n",
      "     |      Return the contents of the corpus citation.bib file, if it exists.\n",
      "     |  \n",
      "     |  encoding(self, file)\n",
      "     |      Return the unicode encoding for the given corpus file, if known.\n",
      "     |      If the encoding is unknown, or if the given file should be\n",
      "     |      processed using byte strings (str), then return None.\n",
      "     |  \n",
      "     |  ensure_loaded(self)\n",
      "     |      Load this corpus (if it has not already been loaded).  This is\n",
      "     |      used by LazyCorpusLoader as a simple method that can be used to\n",
      "     |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      "     |      do help(some_corpus).\n",
      "     |  \n",
      "     |  license(self)\n",
      "     |      Return the contents of the corpus LICENSE file, if it exists.\n",
      "     |  \n",
      "     |  open(self, file)\n",
      "     |      Return an open stream that can be used to read the given file.\n",
      "     |      If the file's encoding is not None, then the stream will\n",
      "     |      automatically decode the file's contents into unicode.\n",
      "     |      \n",
      "     |      :param file: The file identifier of the file to read.\n",
      "     |  \n",
      "     |  readme(self)\n",
      "     |      Return the contents of the corpus README file, if it exists.\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  root\n",
      "     |      The directory where this corpus is stored.\n",
      "     |      \n",
      "     |      :type: PathPointer\n",
      "\n",
      "FUNCTIONS\n",
      "    find_corpus_fileids(root, regexp)\n",
      "    \n",
      "    tagged_treebank_para_block_reader(stream)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['CorpusReader', 'CategorizedCorpusReader', 'PlaintextCorpus...\n",
      "\n",
      "FILE\n",
      "    c:\\programdata\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.corpus.reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
